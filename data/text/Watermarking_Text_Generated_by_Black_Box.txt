Watermarking Text Generated by Black-Box Language Models
Xi Yang
University of Science and Technology of China
yx9726@mail.ustc.edu.cn
Kejiang Chen∗
Weiming Zhang∗
University of Science and Technology of China
{chenkj|zhangwm}@ustc.edu.cn
Chang Liu
Yuang Qi
University of Science and Technology of China
{hichangliu|qya7ya}@mail.ustc.edu.cn
Jie Zhang
Nanyang Technological University
jie_zhang@ntu.edu.sg
Han Fang
National University of Singapore
fanghan@nus.edu.sg
Nenghai Yu
University of Science and Technology of China
ynh@ustc.edu.cn
ABSTRACT
Large language models now exhibit human-like skills in different
fields, leading to worries about misuse like spreading misinforma-
tion and enabling academic dishonesty. Thus, detecting generated
text is crucial. However, passive detection methods that train text
classifiers are stuck in domain specificity and limited adversarial ro-
bustness. To achieve reliable detection, a watermark-based method
was proposed for white-box language models, allowing them to
embed watermarks during text generation. The method involves
randomly dividing the model’s vocabulary to obtain a special list
and adjusting the output probability distribution to promote the
selection of words in the list at each generation step. A detection al-
gorithm aware of the special list can identify between watermarked
and non-watermarked text. However, this method is not applicable
in many real-world scenarios where only black-box language mod-
els are available. For instance, third-parties that develop API-based
vertical applications cannot watermark text themselves because
API providers only supply generated text and withhold probability
distributions to shield their commercial interests.
To allow third-parties to autonomously inject watermarks into
generated text, we develop a watermarking framework for black-
box language model usage scenarios. Specifically, we first define
a binary encoding function to compute a random binary encod-
ing corresponding to a word. The encodings computed for non-
watermarked text conform to a Bernoulli distribution, wherein the
probability of a word representing bit-1 being approximately 0.5. To
inject a watermark, we alter the distribution by selectively replacing
words representing bit-0 with context-based synonyms that repre-
sent bit-1. A statistical test is then used to identify the watermark.
Experiments demonstrate the effectiveness of our method on both
Chinese and English datasets. Furthermore, results under sentence
re-translation, sentence polishing, word deletion, and synonym
substitution attacks reveal that it is arduous for attackers to remove
the watermark without compromising the original semantics.
KEYWORDS
watermarking; black-box large language models; generated text
detection
1
INTRODUCTION
Recent advances in large language models (LLMs) have enabled
them to reach human-level proficiency across numerous profes-
sional and academic tasks [24, 26, 33]. One of the most impressive
∗Corresponding authors. Our code will be available at https://github.com/Kiode/Text_
Watermark_Language_Models.
Classifier
Generated
Human-written
Watermark
Injection
Watermarked
Non-watermarked
“… We then employ  a 
statistical test to detect 
the watermark …“
Language 
Model
Black-box
Generated
Text
Human-written
Text
“… We then use a 
statistical test to identify 
the watermark …”
“… The watermark detection 
technique involves the use of 
a hypothesis test …”
Generated Text
Watermarked Generated Text
Watermarked Generated Text
Language 
Model
White-box
Detector
Detector
Watermarked
Non-watermarked
①Passive Detection (Black-box Scenarios)
Training
“… We then employ  a 
statistical test to detect 
the watermark …”
Generated Text
②Watermark-based Detection (Black-box Scenarios)
③Watermark-based Detection (White-box Scenarios)
Dataset
by modifying the already generated text. 
by modifying the output probability distribution.
Figure 1: Flowchart of different generated text detection
methods, top to bottom: Passive detection, watermark-based
detection (our method) in black-box model scenarios, and
watermark-based detection in white-box model scenarios.
examples is OpenAI’s ChatGPT [23], which has demonstrated re-
markable prowess in answering questions, composing emails, es-
says, and even generating code. However, this impressive ability
to create human-like text with remarkable efficiency has ignited
apprehension regarding the potential abuse of LLMs for malicious
purposes [6, 7, 15, 31], such as phishing, disinformation campaigns,
and academic dishonesty. Several countries and institutions have
imposed bans on ChatGPT, citing concerns about privacy breaches,
ideological influences, and academic dishonesty [19, 20]. Addition-
ally, media outlets have cautioned the public regarding the pos-
sibility of misleading information generated by LLMs [9]. These
growing concerns have cast a shadow on the positive applications
of LLMs. Therefore, detecting and authenticating generated text
becomes crucial to ensure the responsible and secure use of LLMs.
A prevalent solution is passive detection [1, 10, 18, 25, 28, 40],
where a text classifier, usually fine-tuned on a pretrained language
model like RoBERTa [16] and GPT-2 [30], is adopted to distin-
guish between generated and human-written text. However, these
learning-based methods perform well only when the input data
share a similar distribution with the training data, thereby limiting
their applicability to specific domains. Moreover, as LLMs advance
rapidly and human reliance on generated content grows, the line
between human-written and generated text will gradually become
more indistinct. For example, in the evaluations on a “challenge
set” of English texts, OpenAI’s text classifier only identifies 26%
of generated text [25]. Besides, these classifiers are vulnerable to
adversarial attacks [11, 29, 38] and are biased against non-native
language writers [14], causing more false positives and negatives.
To achieve more reliable detection, Kirchenbauer et al. [12] pro-
posed a watermark-based detection method for white-box language
arXiv:2305.08883v1  [cs.CL]  14 May 2023

Xi Yang, Kejiang Chen, Weiming Zhang, Chang Liu, Yuang Qi, Jie Zhang, Han Fang, and Nenghai Yu
model usage scenarios. The watermark is injected by selecting a
random set of “greenlist” words from the model’s vocabulary, and
softly facilitating the generation of words in the greenlist during the
sampling process. This results in a significantly increased frequency
of greenlist words within the generated text, allowing for water-
mark detection through a statistical test. Unlike passive detection
methods, watermark-based methods do not rely on any human-
written and generated text-writing features, as Figure 1 shows.
Besides, the statistical test-based detection is more transparent and
intelligible. However, in real-world scenarios where only black-box
language models are available, manipulating the probability distri-
bution of the model’s vocabulary and intervening in the generation
process are not feasible, limiting the applicability of this method.
For instance, third-parties that develop vertical applications (e.g.,
healthcare, finance) using APIs are unable to embed watermarks
into text on their own, as the APIs only provide generated text with-
out probability distributions. Addressing this limitation is crucial,
as the main market opportunity for LLMs is to serve as platforms
for developing vertical applications [17]. Furthermore, several po-
litical entities are drafting policies requiring application providers
to label their generated content [21, 22] , which is a prerequisite
for obtaining approval to launch vertical applications.
To enable third-parties using black-box language models to au-
tonomously watermark text for the purpose of detection or au-
thentication, we propose a watermarking framework for injecting
watermarks into the already generated text. Our method begins
with constructing a binary encoding function that computes a ran-
dom binary representation (either bit-0 or bit-1) for a given word,
based on the hash value of the word and its immediately preced-
ing word in the text. Given that a well-designed hash function
provides nearly uniformly distributed outputs, the binary encod-
ings derived from each word in a common text are expected to
approximate a Bernoulli distribution [8] with equal probabilities
of 0.5 for a word representing bit-0 and bit-1. Then, we inject the
watermark by selectively substituting words signifying bit-0 with
synonyms representing bit-1. This leads to a higher proportion of
bit-1 occurrences within the binary encodings derived from the
watermarked text. To maintain the original semantics during wa-
termark insertion, we employ BERT [5] to produce context-based
synonyms and introduce sentence-level and word-level similarity
assessments to select high-quality synonyms. Lastly, leveraging the
prior knowledge of the differences in the binary encoding distribu-
tions between watermarked and non-watermarked text, we use a
statistical test to detect the watermark in text. Experiments demon-
strate the effectiveness of our method in injecting authentication
watermarks in both Chinese and English text while maintaining
the semantic integrity. Considering that in the real world, humans
may post-process the text and attackers may attempt to remove the
watermark by modifying the text, we evaluate the robustness of
our method against sentence-level attacks (i.e., re-translation and
polishing) and word-level attacks (i.e., word deletion and synonym
substitution). The results indicate that it is difficult to remove our
watermark without compromising the original semantics.
By the way, the abstract of this paper contains an invisible wa-
termark that can be identified by our watermark detector with a
statistical significance level of 99%.
Main Contributions. In summary, our main contributions are:
• We present a framework for injecting authentication water-
marks into text generated by black-box language models. This
enables third-parties that employ black-box model services (e.g.,
APIs) to autonomously detect or authenticate their generated
content through watermarking.
• We design a context-based synonym generation algorithm and a
watermark-driven synonym sampling algorithm to achieve wa-
termark injection without compromising the original semantics.
Considering different detection time preferences, we provide a
detection algorithm with two optional modes: a fast mode for
quicker results and a precise mode for enhanced precision.
• Extensive experiments on both Chinese and English datasets
showcase that our method can effectively watermark natural
text while preserving the original semantics. Moreover, we sim-
ulate potential attacks (i.e., re-translation, polishing, word dele-
tion, and synonym substitution) to illustrate the difficulty in
erasing the watermark without degrading the semantic quality.
2
BACKGROUND AND RELATED WORKS
2.1
Large Language Models
The advent of the transformer architecture [34] has led to a par-
adigm shift in natural language processing, with large language
models (LLMs) human-like proficiency in various tasks [42]. We
introduce here two types of LLMs relevant to this paper, i.e., au-
toregressive LLMs and autoencoding LLMs.
Autoregressive LLMs. Autoregressive LLMs, such as GPT-3 [3],
generate text by predicting the next word in a sequence based on
the previous words. The model is trained on a large corpus of text
to learn the statistical patterns and relationships between words.
During training, the model’s parameters are optimized to minimize
the negative log-likelihood of the training data, which is equivalent
to maximizing the likelihood of the target sequence given the input
sequence. Mathematically, the training objective is represented as:
L𝑎𝑟= −
𝑛
∑︁
𝑡=1
log 𝑃(𝑤𝑡|𝑤1,𝑤2, . . . ,𝑤𝑡−1;𝜃𝑎𝑟)
(1)
where 𝑤𝑡denotes the word at position 𝑡, and 𝜃𝑎𝑟represents the
model parameters. During text generation, the model samples
the next word 𝑤𝑡from the conditional probability distribution
𝑃(𝑤𝑡|𝑤1,𝑤2, . . . ,𝑤𝑡−1) over the full vocabulary at each time step.
Different sampling strategies [35] can be used to control the trade-
off between diversity and coherence in the generated text.
Autoencoding LLMs. Autoencoding LLMs, such as BERT [5], are
trained with a masked language modeling (MLM) objective, which
aims to predict missing words in a given context. Unlike autoregres-
sive models that predict words sequentially, autoencoding models
focus on capturing bidirectional context by simultaneously condi-
tioning on words before and after the target word. During training,
the model is presented with text where some words have been
randomly masked, and the objective is to predict the original words
based on their surrounding context. The training objective is to
maximize the likelihood of predicting the masked words correctly

Watermarking Text Generated by Black-Box Language Models
based on their surrounding context:
L𝑎𝑒= −
∑︁
𝑡∈M
log 𝑃(𝑤𝑡|𝑤1,𝑤2, . . . ,𝑤𝑡−1,𝑤𝑡+1, . . . ,𝑤𝑛;𝜃𝑎𝑒)
(2)
where 𝜃𝑎𝑒represents the model parameters, 𝑤1,𝑤2, . . . ,𝑤𝑛are
words in the text, and M denotes the set of masked positions.
In BERT, each word is first tokenized and represented as a one-
hot vector. This one-hot vector is then multiplied by an embedding
matrix to produce the initial word embedding. The initial embed-
ding is combined with positional and segment embeddings before
being fed into the transformer encoder. The transformer encoders
update the embeddings by iteratively applying self-attention and
feedforward layers to capture the bidirectional context of each word.
Specifically, the final hidden state corresponding to a masked word
is fed into an output layer with a softmax activation function to
produce a probability distribution over the vocabulary. The model
predicts the masked word by selecting the word with the highest
probability. The bidirectional context encoding allows BERT to ex-
cel in tasks that necessitate a deep understanding of the context,
which is why we employ it to generate synonyms in our method.
2.2
Recent Generated Text Detection Methods
Statistical Discrepancy Detection. Several methods distinguish
between generated and human-written text by identifying statisti-
cal discrepancies between them, as exemplified by two recent tools:
GPTZero [40] and DetectGPT [18]. GPTZero uses perplexity and
burstiness to tell apart human-written and generated text, as lan-
guage models tend to produce more predictable and consistent text
based on the patterns they learned from training data, resulting in
lower perplexity scores for generated text. DetectGPT exploits the
negative curvature regions of a model’s log probability function to
identify generated text by comparing the log probability of unper-
turbed and perturbed text variations. However, as language models
are constantly improving and becoming more sophisticated, these
heuristic features struggle to achieve robustness and generalization.
Deep Learning-based Detection. Deep learning-based methods
rely on gathering human-written and generated samples to train
classifiers. Recently, OpenAI fine-tuned a GPT model for this dis-
crimination task using a dataset comprising paired human and
AI-generated texts on identical topics [25]. Similarly, Guo et al. [10]
fine-tuned a text classifier based on pre-trained autoencoding LLMs
(e.g., RoBERTa) by collecting the Human ChatGPT Comparison
Corpus (HC3). Deep learning-based methods exhibit strong perfor-
mance under the training data distribution, but they are susceptible
to adversarial attacks, lack interpretability, and struggle to provide
reliable judgments in human-AI collaboration scenarios.
Watermark-based Detection. Kirchenbauer et al. [12] proposed
the watermarking framework for white-box language models. The
watermarking operates by randomly selecting a random set of
"greenlist" words from the model’s vocabulary and softly encour-
aging the use of these "greenlist" words by interfering with the
sampling process at each generation step. The watermark can be
detected by testing the following null hypothesis,
𝐻0: The text sequence is generated with no knowledge of the
selection rule of "greenlist" words.
If the null hypothesis is rejected, it can be concluded that the text
was generated by the given model. This method is suitable for
model owners who have access to the model’s output probability
distribution and can interfere with the sampling process. However,
it is not feasible for third parties who develop vertical applications
using black-box language model services (e.g., APIs) and do not
have access to the model’s internals, even though they also have a
need to embed watermarks in text generated from them.
2.3
Multi-Bit Text Watermarking Methods
Traditional text watermarking tries to embed a multi-bit watermark
within the text, aiming to facilitate tracing the text provenance. Ab-
delnabi and Fritz [2] proposed a transformer-based encoder-decoder
network, named AWT, that can embed fixed-length watermark in-
formation in English text. The network learns to replace inconspic-
uous words (e.g., prepositions, conjunctions, and symbols) with
similar alternatives to encode information, resulting in a robust
watermark that can be extracted even if some words are altered, pro-
vided the inconspicuous words remain intact. However, although
the authors introduced sentence embedding constraints to maintain
the semantic quality of the watermarked text, the network did not
genuinely focus on semantic quality. Instead, it learned to modify
words with minimal impact on sentence embedding (such as prepo-
sitions and symbols), leading to watermarked text with numerous
grammatical errors and distortions. Additionally, sentence-level
attacks (e.g., polishing, rearranging sentence order) can result in
the disorder and length changes of the extracted bits, causing the
watermark bits to lose synchronization.
Yang et al. [39] proposed a synonym substitution algorithm for
embedding a multi-bit watermark within a given text. This method
offers superior semantic quality compared to AWT. However, it
requires the watermark embedder and extractor to locate the same
words and generate identical synonyms to achieve successful wa-
termarking. Moreover, their watermarking algorithm is highly sen-
sitive to context changes, any slight alteration of the context may
cause the watermark bits to be desynchronized and unextractable.
3
MOTIVATION
Our objective is to design a framework that enables text generation
service providers to perform watermark injection and detection in
the text generated from black-box language models (where only
model outputs are observable, rather than parameters or internal
computations). In this paper, we primarily consider two entities:
the attacker and the text generation service provider. The attacker
seeks to exploit the generated text for malicious purposes, while the
service provider aims to detect or authenticate the text by verifying
the presence of a watermark, thus helping to mitigate the abuse
of its services. The attacker may post-process the generated text
without compromising the original semantics. But they will not
completely rewrite the text, as doing so contradicts the purpose
of using the text generation service. Therefore, the watermarking
framework should have the following properties:
• Fidelity: The injection of a watermark should not affect the
original semantic information.
• Robustness: Attackers should not be able to erase the water-
mark without compromising the original semantic information.

Xi Yang, Kejiang Chen, Weiming Zhang, Chang Liu, Yuang Qi, Jie Zhang, Han Fang, and Nenghai Yu
“… We then employ a statistical test to detect the watermark …”
Context-based Synonyms Generation
employ
use
apply
require
develop
…
0
1
0
0
1
…
Synonyms
Binary Encoding
“… We then use a statistical test to detect the watermark …”
…
“… We then use a statistical test to detect the watermark …”
detect
identify
locate
trace
assess
…
0
1
1
0
1
…
Synonyms
Binary Encoding
“… We then use a statistical test to identify the watermark …”
Generated Text
Watermarked 
Text
Watermark-driven  Synonym Sampling
Watermark-driven  Synonym Sampling
Context-based Synonyms Generation
Watermark Injection
Watermark Detection
Watermarked
Non-watermarked
𝐻0: 𝑇ℎ𝑒𝑜𝑏𝑠𝑒𝑟𝑣𝑒𝑑𝑏𝑖𝑛𝑎𝑟𝑦𝑒𝑛𝑐𝑜𝑑𝑖𝑛𝑔𝑠𝑜𝑐𝑐𝑢𝑟𝑟𝑎𝑛𝑑𝑜𝑚𝑙𝑦.
“… We then employ a statistical test to detect the watermark …”
POS Filter
Iterations
Language 
Model
Black-box
Detector
Non-watermarked Text
Watermarked Text
Figure 2: The proposed watermarking framework.
• Generality: The watermarking framework should work for text
written in different languages and covering different topics.
4
OUR METHOD
In this section, we will elaborate the proposed watermarking frame-
work. As illustrated in Figure 2, once we acquire the original gen-
erated text from a black-box language model, we selectively and
sequentially replace words with synonyms to inject the watermark.
Specifically, we first construct a binary encoding function that com-
putes a random binary representation (either bit-0 or bit-1) for a
given word. This function possesses a notable property: in a non-
watermarked text, the number of words representing bit-0 and bit-1
are nearly balanced. Then, for each selected word, we first generate
its context-based synonym candidates and compute the random
binary encoding carried by each candidate. Then, we develop a
watermark-driven synonym sampling algorithm to encourage the
selection of candidates representing bit-1 to inject the watermark.
The injected watermark results in a relatively higher proportion of
words representing bit-1. Therefore, we can employ a statistical test
to detect the presence of a watermark. Subsequently, we present a
comprehensive explanation of the binary encoding function and
the watermarking process.
4.1
Binary Encoding Function
Here, we design the binary encodings to express watermark infor-
mation within the text. Let 𝑤𝑖denotes the 𝑖-th word in the text, and
ℎ(·) represents the string hash function. We utilize the combined
hash of the current word and its preceding word as a seed for gen-
erating a random binary value corresponding to 𝑤𝑖. By including
the preceding word, we ensure that a word demonstrates variability
in expressing bit-0 and bit-1 under different contexts. This can be
formalized as follows:
𝑏𝑖= RandomBinary(ℎ(𝑤𝑖) ⊕ℎ(𝑤𝑖−1)),
𝑖= 2, . . . ,𝑛
(3)
where ⊕denotes the bitwise XOR operation, and𝑏𝑖represents the bi-
nary encoding corresponding to𝑤𝑖. The function RandomBinary(𝑥)
produces a random bit based on the input seed.
Owing to the near-uniform nature of the hash function, the
original text should exhibit a roughly equal distribution of words
representing bit-0 and bit-1. Building on this, we propose to inject
the watermark by altering the distribution, raising the proportion
of words representing bit-1. Then, we can determine whether the
text contains a watermark using a statistical testing method.
4.2
Watermark Injection
The watermark injection begins with the second word of the input
text and proceeds sequentially to the last word. Specifically, for the𝑖-
th word 𝑤𝑖in text, we first compute its part-of-speech (POS), which
is a linguistic category that refers to the syntactic role of a word
in a sentence. If 𝑤𝑖fails to pass through our POS filter, indicating
that it belongs to a category that is unsuitable for substitution, we
skip this word. If 𝑤𝑖passes the POS filter and its corresponding
binary encoding is bit-0, we generate synonym candidates for 𝑤𝑖
and replace it with a selected synonym that represents bit-1 using
our watermark-driven synonym sampling algorithm.
POS Filter. To assess whether a word is eligible for substitution, we
employ language-specific exclusion lists, which are customized to
accommodate the unique features of various languages and contexts.
For English, our exclusion list encompasses pronouns, prepositions,
conjunctions, proper nouns, punctuation marks, quantifiers, per-
sonal names, place names, and other proprietary terms. For Chinese,
the exclusion list is composed of auxiliary words, proper nouns,
punctuation marks, quantifiers, personal names, place names, and
other proprietary terms. The exclusion list can be customized to
accommodate specific needs and situations.
Context-based Synonym Generation. Since BERT’s pre-training
task involves predicting masked words within a text, it is well-suited
for synonym generation. However, directly masking the target word
will lose the information conveyed by the word itself, causing BERT
to generate less suitable candidates for synonym substitution. To
enable BERT to leverage both the contextual information and the
target word’s information when generating synonyms, inspired by
Zhou et al. [43], we apply random dropout to the word embedding
of the target word, resulting in a partially masked word. Given
the original word 𝑤𝑖in text T = (𝑤1,𝑤2, ...,𝑤𝑖, ...𝑤𝑛), we apply
random dropout to the word embedding of 𝑤𝑖to create a partially
masked version, ˜𝑤𝑖. We then feed the partially masked embeddings
into BERT to predict the initial set of synonym candidates, denoted
as 𝐶= {𝑠1,𝑠2, ...,𝑠𝐾}, representing top-𝐾words predicted by BERT.
Nonetheless, since the BERT model is trained unsupervised on
a large-scale corpus, it can only estimate the statistical similarity
between two words (i.e., the likelihood of co-occurring in the same
context). As a result, it might consider antonyms as ‘similar’, since

Watermarking Text Generated by Black-Box Language Models
they frequently appear in similar contexts and share similar syntac-
tic structures. Thus, it is essential to further evaluate the semantic
similarity between words in 𝐶and the original word 𝑤𝑖.
We adopt three metrics to evaluate semantic similarity, namely
sentence embedding similarity (𝑆sent), global word embedding simi-
larity (𝑆global), and contextualized word embedding similarity (𝑆context).
Let T′ denote the text after replacing 𝑤𝑖with a synonym 𝑠from
𝐶. We use the RoBERTa model [16], fine-tuned on the Multi-Genre
Natural Language Inference (MNLI) corpus [37], to obtain sentence
embeddings for the original text (SentEmb(T)) and the text after
replacement (SentEmb(T′)). We then calculate the cosine distance
between these two sentence embeddings:
𝑆sent = cos(SentEmb(T), SentEmb(T′))
(4)
To obtain the global word embeddings, we consult the open-
source Word-to-Vec models like GloVe [27]. The similarity between
the global word embeddings of the candidate word and the original
word can be expressed as:
𝑆global = cos(w2v(𝑤𝑖), w2v(𝑠))
(5)
where w2v(·) denotes the use of the Word-to-Vec model to obtain
the embedding of the input word and 𝑠means the synonym.
To compute the contextualized word embedding similarity using
BERT, we denote the contextualized representation of a word 𝑥at
the 𝑙-th layer of BERT as 𝑓𝑙(𝑥,𝑐). Here, 𝑐refers to the context in
which 𝑥appears.
𝑆context = 1
𝐿
𝐿
∑︁
𝑙=1
cos(𝑓𝑙(𝑤𝑖,𝑐𝑇), 𝑓𝑙(𝑠,𝑐𝑇′))
(6)
We use the last 8 hidden layers (𝐿= 8) of BERT for computing
the contextualized word embedding similarity, considering that
different layers of BERT can attend to different dimensions of se-
mantic features [36]. To provide a more comprehensive measure of
word-level similarity, we calculate the weighted average of 𝑆global
and 𝑆context:
𝑆word = 𝜆𝑆context + (1 −𝜆)𝑆global
(7)
where 𝜆is the relative weight, with value ranging between 0 and 1.
Then, we further filter the candidates in 𝐶according to their
𝑆sent and 𝑆word scores. Specifically, we set a sentence-level similar-
ity threshold (𝜏𝑠𝑒𝑛𝑡) and a word-level similarity threshold (𝜏𝑤𝑜𝑟𝑑).
Given candidate set 𝐶= {𝑠1,𝑠2, ...,𝑠𝐾}, sentence-level similarity
score 𝑆sent, and word-level similarity score 𝑆word, the filtered can-
didate set 𝐶′ is:
𝐶′ = {𝑠∈𝐶| 𝑆sent(𝑠,𝑤𝑖) ≥𝜏sent and 𝑆word(𝑠,𝑤𝑖) ≥𝜏word}
(8)
Here, 𝑠is the synonym candidate, 𝑤𝑖is the original word. Following
this, we design a synonym sampling algorithm that utilizes the
synonyms in 𝐶′ to inject a watermark into text T.
Watermark-Driven Synonym Sampling. For each candidate 𝑠′
𝑘
in the filtered set 𝐶′ = {𝑠′
1,𝑠′
2, ...,𝑠′
𝐾′}, we compute the binary en-
coding represented by 𝑠′
𝑘in the current text:
𝑏𝑘= RandomBinary(ℎ(𝑠′
𝑘) ⊕ℎ(𝑤𝑖−1)),
𝑘= 2, . . . , 𝐾′
(9)
Here, 𝑏𝑘is the binary encoding, ℎ(·) is a hash function, and 𝑤𝑖−1 is
the preceding word in the text. Then, we select the candidate with
Algorithm 1 Watermark Injection
1: procedure WatermarkInjection(T)
⊲T = {𝑤1, 𝑤2, ..., 𝑤𝑛}
2:
for 𝑖∈{2, 3, . . . ,𝑛} do
3:
𝑏𝑖←RandomBinary(ℎ(𝑤𝑖) ⊕ℎ(𝑤𝑖−1))
4:
if POSFilter(𝑤𝑖) and 𝑏𝑖== 0 then
5:
𝐶←SynonymsGeneration(T, 𝑤𝑖)
6:
𝐶′ ←FilterCandidates(T,𝐶, 𝑤𝑖)
7:
𝑠𝑠𝑒𝑙𝑒𝑐𝑡𝑒𝑑←SynonymSampling(T,𝐶′, 𝑤𝑖)
8:
Replace 𝑤𝑖with 𝑠𝑠𝑒𝑙𝑒𝑐𝑡𝑒𝑑in T
9: function POSFilter(𝑤𝑖)
10:
if 𝑃𝑂𝑆(𝑤𝑖) is in 𝐸𝑥𝑐𝑙𝑢𝑠𝑖𝑜𝑛𝐿𝑖𝑠𝑡then
11:
return False
12:
else
13:
return True
14: function SynonymsGeneration(T, 𝑤𝑖)
15:
Partially mask 𝑤𝑖as ˜𝑤𝑖
16:
Input ˜𝑤𝑖with context to BERT and predict candidate words 𝐶
17:
return 𝐶
18: function FilterCandidates(T,𝐶, 𝑤𝑖)
19:
Initialize an empty set 𝐶′
20:
for each 𝑠∈𝐶do
21:
Replace 𝑤𝑖with 𝑠to get T′
22:
𝑆sent ←cos(SentEmb(T), SentEmb(T′))
23:
𝑆global ←cos(w2v(𝑤𝑖), w2v(𝑠))
24:
𝑆context ←1
𝐿
Í𝐿
𝑙=1 cos(𝑓𝑙(𝑤𝑖,𝑐𝑇), 𝑓𝑙(𝑠,𝑐𝑇′))
25:
𝑆word ←𝜆𝑆context + (1 −𝜆)𝑆global
26:
if 𝑆sent ≥𝜏sent and 𝑆word ≥𝜏word then
27:
Append 𝑠to 𝐶′
28:
return 𝐶′
29: function SynonymSampling(T,𝐶′, 𝑤𝑖)
30:
for each 𝑠′
𝑘∈𝐶′ do
31:
Compute 𝑏𝑘using Eq. (9)
32:
𝑠𝑠𝑒𝑙𝑒𝑐𝑡𝑒𝑑←arg max𝑠′
𝑘∈𝐶′ {𝑆word(𝑠′
𝑘, 𝑤𝑖) | 𝑏𝑘= 1}
33:
return 𝑠𝑠𝑒𝑙𝑒𝑐𝑡𝑒𝑑
a binary encoding of bit-1 and the highest 𝑆word to replace 𝑤𝑖. Let
the selected candidate be 𝑠𝑠𝑒𝑙𝑒𝑐𝑡𝑒𝑑. Then, we have:
𝑠𝑠𝑒𝑙𝑒𝑐𝑡𝑒𝑑= arg max
𝑠𝑘∈𝐶′{𝑆word(𝑠𝑘,𝑤𝑖) | 𝑏𝑘= 1}
(10)
We achieve watermark injection at this step by replacing 𝑤𝑖with
𝑠𝑠𝑒𝑙𝑒𝑐𝑡𝑒𝑑. Then, we proceed to the next word, 𝑤𝑖+1, and perform the
same watermark injection operation, iterating until the last word. In
Algorithm 1, we provide the complete watermark injection process.
4.3
Watermark Detection
As described in §4.1, for each word in the non-watermarked text,
the probability of representing bit-0 and bit-1 is nearly 0.5. During
watermark injection, we employ the synonym sampling algorithm
to increase the occurrence of words representing bit-1. Thus, wa-
termark detection can be accomplished by examining the following
null hypothesis:
𝐻0: The observed binary encodings occur randomly.

Xi Yang, Kejiang Chen, Weiming Zhang, Chang Liu, Yuang Qi, Jie Zhang, Han Fang, and Nenghai Yu
To verify the null hypothesis 𝐻0, we calculate the following test
statistic:
𝑍=
( ˆ𝑝−𝑝0)
√︃
𝑝0(1−𝑝0)
𝑁
(11)
where ˆ𝑝is the proportion of words representing bit-1, 𝑝0 = 0.5
represents the expected proportion under the null hypothesis (i.e.,
random binary encodings), and 𝑁is the total number of binary en-
codings derived from the text. We then compare the test statistic 𝑍
with the critical value 𝑍𝛼corresponding to the chosen significance
level 𝛼. The significance level, denoted by 𝛼, is the probability of re-
jecting the null hypothesis when it is true, thereby determining the
threshold for a statistically significant result. If 𝑍> 𝑍𝛼, we reject
the null hypothesis and conclude that the observed binary encod-
ings are significantly different from random encodings, indicating
the presence of a watermark.
We offer two optional watermark detection modes, called fast
detection and precise detection. Fast detection simply computes
the binary encodings for words passing the POS filter and then
conducts the hypothesis test. Precise detection further selects words
highly likely to carry watermark information before performing
the hypothesis test, leading to a more accurate detection scope. The
pseudocode for both fast and precise detection modes can be found
together in Algorithm 2. For a more intuitive understanding, we
also provide examples of each mode in Table 1.
Fast Detection. For the text under inspection, we begin with the
second word and assess whether its POS can pass our POS filter. If it
fails, we skip this word; otherwise, we compute its binary encoding
and continue the operation iteratively until the last word. After
acquiring the binary encodings, we calculate the 𝑍-score according
to Eq.(11) to determine if the text contains a watermark.
Precise Detection. An enhanced detection can be devised by lever-
aging our prior knowledge of the watermark injection. The fast
detection compute binary encodings from all words passing through
the POS filter, potentially including words lacking high-quality syn-
onyms. This could lead to the inclusion of words, which were not
replaced during the watermark injection and represent bit-0, in the
hypothesis test of fast detection. Therefore, we can improve detec-
tion performance by computing binary encodings and performing
hypothesis test only for words that are likely to have high-quality
synonyms. Specifically, for each word that passes through the POS
filter, we generate its synonym candidates with the same process
in watermark injection (§4.2). If the candidate set 𝐶′ is empty, we
assume that the word is less likely to be modified during the water-
mark injection and exclude it from the test scope. Otherwise, we
compute its binary encoding and then perform the same operation
on the next word until the last word. After computing the binary
encodings for all these words, we calculate the 𝑍-score to determine
if the text contains a watermark.
The precise detection offers more accurate watermark detection,
but it comes with a higher computational cost due to the need to
generate synonyms. Users can choose the optimal detection mode
based on their preferred detection time.
Algorithm 2 Watermark Detection
1: procedure FastDetection(T)
⊲T = {𝑤1, 𝑤2, ..., 𝑤𝑛}
2:
Initialize binary encoding count 𝑁←0
3:
Initialize bit-1 encoding count 𝑐←0
4:
for 𝑖∈{2, 3, . . . ,𝑛} do
5:
if POSFilter(𝑤𝑖) then
6:
Compute 𝑏𝑘using Eq. (9)
7:
𝑁←𝑁+ 1
8:
if 𝑏𝑘= 1 then
9:
𝑐←𝑐+ 1
10:
Compute test statistic 𝑍using Eq. (11)
11:
Compare 𝑍with the critical value 𝑍𝛼
12:
return watermark presence decision
13: procedure PreciseDetection(T)
14:
Initialize binary encoding count 𝑁←0
15:
Initialize bit-1 encoding count 𝑐←0
16:
for 𝑖∈{2, 3, . . . ,𝑛} do
17:
if POSFilter(𝑤𝑖) then
18:
𝐶←SynonymsGeneration(T, 𝑤𝑖)
19:
𝐶′ ←FilterCandidates(T,𝐶, 𝑤𝑖)
20:
if 𝐶′ ≠∅then
21:
Compute 𝑏𝑘using Eq. (9)
22:
𝑁←𝑁+ 1
23:
if 𝑏𝑘= 1 then
24:
𝑐←𝑐+ 1
25:
Compute test statistic 𝑍using Eq. (11)
26:
Compare 𝑍with the critical value 𝑍𝛼
27:
return watermark presence decision
5
EXPERIMENTAL EVALUATION
5.1
Experimental Setup
Datasets. To evaluate our method, we primarily utilize the Human
ChatGPT Comparison Corpus (HC3) from [10]. The HC3 dataset of-
fers a crucial resource for examining linguistic and stylistic features
of both human-written and ChatGPT-generated text in Chinese
and English. We select the ChatGPT answers for evaluation. Specif-
ically, we gather 200 samples from each of the following English
subcategories: wiki_csai, open_qa, medicine, and reddit_eli5.
Each English sample has a length of 200±5 words. In total, we
obtain 800 samples to serve as our English dataset. Likewise, we
choose 800 samples from the equivalent Chinese subcategories, in-
cluding baike, open_qa, medicine, and nlpcc_dbqa. Each Chinese
sample has a length of 200±5 characters. Note that the information-
carrying capacity of 200 Chinese characters and 200 English words
is different, and there are performance variations between Chinese
and English language models. Thus, the results will exhibit subtle
differences on these two languages.
Implementation Details. We utlize the SHA-256 hashing algo-
rithm to construct the binary encoding function. In English ex-
periments, we adopt the BERT model (bert-base-cased [5]) for
synonym generation and contextualized word similarity computa-
tion. The RoBERTa model (roberta-large-mnli [16]) is employed
for sentence similarity calculation, while the Word-to-Vec model
(glove-wiki-gigaword-100 [27]) is used for global word similarity
assessment. Similarly, in Chinese experiments, we employ the word-
level Chinese BERT model (wobert_chinese_plus_base [32]), the

Watermarking Text Generated by Black-Box Language Models
Table 1: Examples of watermark detection. Red-highlighted words represent bit-0 and green ones bit-1; underlining shows the
scope of precise detection. The 𝑝-value indicates the likelihood of the text not containing a watermark.
Text Content
𝑝-value
Fast
Precise
Original
Flocking is a type of coordinated group behavior that is exhibited by animals of various species, including birds,
fish, and insects. It is characterized by the ability of the animals to move together in a coordinated and cohesive
manner, as if they were a single entity. Flocking behavior is thought to have evolved as a way for animals to
increase their chances of survival by working together as a group. For example, flocking birds may be able to locate
food more efficiently or defend themselves against predators more effectively when they work together.
0.9933
0.9646
Watermarked
Flocking is a kind of coordinated team behavior that is exhibited by animals of several species, notably birds, fish,
and insects. It is characterized by the ability of the animals to move together in a coordinated and cohesive
way, as if they were a single entity. Flocking behavior is believe to have evolved as a way for animals to
raise their likelihood of survival by working together as a group. For instance, flocking birds could be able to locate
nutrition more efficiently or defend themselves against predators more effectively when they work together.
0.0342
0.00004
Original
当你想向中国女孩子说出第一句话时，你应该先考虑一些基本的礼貌，例如问她的名字或者问她是否愿意和
你交谈。你也可以先说出你自己的名字，然后问她是否愿意认识你。你可以说："你好，我叫XXX，你叫
什么名字？你愿意和我聊一聊吗？" 如果你暗恋中的女孩子是你的朋友，你可以先尝试着和她更多地交流
0.4443
0.4287
Watermarked
当你想向中国妹子说出第一句话时，你应该先考虑一些基本的礼貌，例如问她的名字或者询问她是否愿意和
你交谈。你也可以首先说出你自己的名字。然后问她是否愿意认识你。你可以说："你好，我叫做XXX,你叫
什么名字？你愿意和我聊一聊吗？"假如你暗恋中的妹子是你的朋友，你可以首先尝试着和她更多地交流
0.0316
0.0045
0.0
0.2
0.4
0.6
0.8
1.0
False Positive Rate
0.0
0.2
0.4
0.6
0.8
1.0
True Positive Rate
word=0.7 (AUC = 1.00)
word=0.75 (AUC = 0.99)
word=0.8 (AUC = 0.96)
word=0.85 (AUC = 0.80)
(a) English & Fast Detection
0.0
0.2
0.4
0.6
0.8
1.0
False Positive Rate
0.0
0.2
0.4
0.6
0.8
1.0
True Positive Rate
word=0.7 (AUC = 1.00)
word=0.75 (AUC = 1.00)
word=0.8 (AUC = 0.99)
word=0.85 (AUC = 0.94)
(b) English & Precise Detection
0.0
0.2
0.4
0.6
0.8
1.0
False Positive Rate
0.0
0.2
0.4
0.6
0.8
1.0
True Positive Rate
word=0.7 (AUC = 1.00)
word=0.75 (AUC = 0.98)
word=0.8 (AUC = 0.90)
word=0.85 (AUC = 0.70)
(c) Chinese & Fast Detection
0.0
0.2
0.4
0.6
0.8
1.0
False Positive Rate
0.0
0.2
0.4
0.6
0.8
1.0
True Positive Rate
word=0.7 (AUC = 1.00)
word=0.75 (AUC = 0.99)
word=0.8 (AUC = 0.97)
word=0.85 (AUC = 0.87)
(d) Chinese & Precise Detection
Figure 3: ROC curves with AUC (Area Under the Curve) values for watermark detection under different languages,𝜏word values,
and detection modes. An AUC value of 1 indicates perfect classification, while a value of 0.5 implies random chance.
Chinese RoBERTa model (Erlangshen-Roberta-330M-Similarity
[41]), and the Chinese Word-to-Vec model (sgns.merge.word[13]).
Regarding the hyperparameters, we set 𝜆= 0.83 and 𝐾= 32 as
default. The sentence similarity 𝑆sent between the watermarked
text and the original text typically remains stable, as they differ
by merely a few words. The 𝑆sent score will decrease substantially
when antonyms are involved. Therefore, in our primary experi-
ments, we fix 𝜏sent = 0.8 and focus on investigating the impact of
varying 𝜏word values. Moreover, we conduct an ablation study to
assess the roles of 𝜏sent and 𝜏word in semantic quality control.
Metrics. To demonstrate detection performance, we primarily em-
ploy Receiver Operating Characteristic (ROC) curves to present
detection results. ROC curves are graphical plots that showcase
the diagnostic ability of a binary classifier as its discrimination
threshold varies, illustrating the true positive rate against the false
positive rate and offering insights into the sensitivity-specificity
trade-off. Besides, to evaluate robustness, we use 𝑍-score to repre-
sent watermark strength. For fidelity assessment, we employ the
METEOR score [4], a traditional metric widely used in machine
translation to compare output sentences with references which con-
ducts n-gram alignments between reference and output text. Scores
range from 0 to 1 (identical sentences). However, METEOR alone
is insufficient for evaluating semantics, as two sentences with an
equal number of changed words may have similar METEOR scores
but differ in semantics. Thus, we employ the language models (i.e.,
all-MiniLM-L6-v21 for English and Erlangshen-Roberta-330M-Si
milarity2 for Chinese) to approximate semantic similarity between
original and watermarked text.
5.2
Watermark Strength under Different 𝜏word
To investigate the influence of different 𝜏word values on watermark
strength, we perform watermark injection and detection on Chi-
nese and English samples from HC3 dataset using different 𝜏word
values, specifically 0.7, 0.75, 0.8, and 0.85. Under such settings, the
ROC curves in Figure 3 depict the experimental results. As can be
observed, for identical language and detection mode, higher 𝜏word
1https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2
2https://huggingface.co/IDEA-CCNL/Erlangshen-Roberta-330M-Similarity

Xi Yang, Kejiang Chen, Weiming Zhang, Chang Liu, Yuang Qi, Jie Zhang, Han Fang, and Nenghai Yu
English
Similarity
Chinese
Similarity
English
METEOR
Chinese
METEOR
0.00
0.25
0.50
0.75
1.00
Score
word=0.7
word=0.75
word=0.8
word=0.85
Figure 4: Semantic similarity and METEOR scores of water-
marked text compared to the original text under different
𝜏word values.
values result in weaker watermark strength (i.e., smaller AUC val-
ues). This is because higher 𝜏word values enforce stricter constraints
on the generated synonyms, resulting in fewer modifiable words
and weakened watermark strength. On the other hand, lower 𝜏word
values permit more relaxed synonym constraints, yielding more
modifiable words, stronger watermarks, but may compromise the
original semantic quality, which will be discussed in §5.3. Moreover,
with identical language and 𝜏word value, the precise detection sur-
passes the fast detection, indicating that conducting further analysis
on words can effectively enhance the detection capabilities.
5.3
Fidelity Analysis
Semantic Quality.
We present the semantic similarity scores
and METEOR scores for watermarked text in comparison to the
original text under various 𝜏word values in Figure 4. Higher 𝜏word
values result in fewer alterations to the original text, making the
watermarked text closer to the original while maintaining high se-
mantic quality. Furthermore, a decrease in 𝜏word value does not lead
to a significant reduction in semantic similarity because language
models focus more on the overall semantic similarity of the text,
whereas METEOR scores decline more rapidly as they are highly
sensitive to word substitutions. Taking both watermark strength
and semantic quality into consideration, we choose 𝜏word = 0.8 for
English and 𝜏word = 0.75 for Chinese as default values for subse-
quent experiments.
Perplexity Distributions. Perplexity (PPL) is a widely used metric
for evaluating language model performance, defined as the expo-
nential of the negative average log-likelihood of a given text under
the language model. Lower PPL values indicate a more confident
language model. Language models are trained on extensive text
corpora, enabling them to learn common language patterns and
structures. Thus, PPL can be used to assess how well a text conforms
to typical characteristics. We employ Chinese and English GPT-
2 models (Wenzhong-GPT2-110M3 for Chinese and gpt2-medium4
for English) to calculate the perplexity distributions of original
generated text, watermarked generated text, and human-written
text. This allows us to examine the changes introduced by water-
mark injection from the perspective of perplexity. Figure 5 shows
that original generated text exhibits lower PPL values compared
to human-written text, as language models excel at reproducing
common patterns and structures. In contrast, humans can express
3https://huggingface.co/IDEA-CCNL/Wenzhong-GPT2-110M
4https://huggingface.co/gpt2-medium
0
25
50
75
100
125
150
Perplexity
0.00
0.05
0.10
0.15
0.20
0.25
Proportion
Original
Watermarked
Human
(a) English
0
5
10
15
20
Perplexity
0.00
0.05
0.10
0.15
Proportion
Original
Watermarked
Human
(b) Chinese
Figure 5: Perplexity distributions of original generated text,
watermarked generated text, and human-written text.
Neutral
Negative
Positive
0.0
0.2
0.4
0.6
0.8
1.0
Proportion
Original
Watermarked
0.782
0.767
0.215
0.231
(a) English
Neutral
Negative
Positive
0.0
0.2
0.4
0.6
0.8
1.0
Proportion
Original
Watermarked
0.863
0.856
0.116
0.130
(b) Chinese
Figure 6: Sentiment distributions of original and water-
marked text.
themselves in diverse ways, challenging GPT-2’s prediction capabil-
ities. Therefore, human-written text exhibit higher PPL values and
display a long-tailed distribution. Moreover, due to the increased
lexical diversity resulting from our watermark injection, the PPL
distribution of watermarked generated text falls between original
generated text and human-written text.
Sentiment Distributions. We visualize the sentiment of water-
marked and original texts to illustrate that watermark injection has
minimal impact on the original sentiment distribution. We conduct
sentiment analysis on both English and Chinese datasets using a
multilingual sentiment classification model (twitter-xlm-roberta-
base-sentiment5) fine-tuned on a Twitter corpus. By comparing
the sentiment distributions of watermarked and original text in
Figure 6, we observe that the impact of watermark injection on
the overall sentiment is negligible. This finding indicates that our
method effectively preserves the original sentiment of the text
while injecting the watermark, ensuring that the watermarked text
remains true to the intended emotion.
5.4
Qualitative Analysis
Exploring Word Substitutions in Watermark Injection. To
gain deeper insights into the modifications resulting from water-
mark injection, we visualize the subsituted words alongside their
corresponding substitutions. As shown in Figure 7, we display the
most frequently substituted words and their respective substitu-
tions for both English and Chinese. For more complete examples
of original and watermarked texts, please refer to the additional
5https://huggingface.co/cardiffnlp/twitter-xlm-roberta-base-sentiment

Watermarking Text Generated by Black-Box Language Models
Figure 7: Replacement frequency heatmap. Each row begins with an original word, and each cell indicates the frequency of
its corresponding replacement for watermark injection. The color intensity represents the frequency, with darker shades
indicating higher frequencies.
materials. The following observations can be drawn from the visual-
izations:1) Watermark injection does not follow a fixed substitution
rule; instead, it dynamically changes based on the context, meaning
a word is not consistently replaced by a specific substitute. 2) The
substitutions exhibit similarities between English and Chinese but
subtle distinctions arise due to the unique linguistic properties of
each language. For example, English substitutions primarily consist
of verbs, adjectives, and adverbs with distinct roots but similar
meanings, whereas Chinese substitutions display greater flexibil-
ity, encompassing not only verbs, adjectives, adverbs, and nouns
but also conjunctions with multiple equivalent alternatives (e.g.,
“或”-“或者” and “如果”-“假如”).
5.5
Watermark Strength under Different Text
Lengths
We believe that the watermark strength tends to increase as the
text length grows, providing more words available for watermark
injection. To verify this, we select samples of varying lengths (rang-
ing from 50 words to 300 words) in the English dataset, with 800
samples for each length, to perform watermark injection and detec-
tion. Similarly, we select samples of different lengths (ranging from
50 characters to 300 characters) in the Chinese dataset. We employ
𝑍-score to measure watermark strength. As shown in Figure 8, for
both English and Chinese, there is a clear trend showing that as the
text length increases, the watermark strength, represented by the
𝑍-score, also increases. This observation supports that longer texts
offer more opportunities for watermark injection. When compar-
ing the results of fast detection and precise detection, it is evident
that the precise mode consistently yields higher 𝑍-scores across
all text lengths for both languages. Moreover, as the text length in-
creases, the enhancement in detection performance becomes more
significant compared to shorter texts.
50
100
150
200
250
300
Text Length (English/words)
0
2
4
6
Z-score
Fast Detection
Precise Detection
(a) English
50
100
150
200
250
300
Text Length (Chinese/characters)
0
2
4
6
Z-score
Fast Detection
Precise Detection
(b) Chinese
Figure 8: Watermark strength under different text lengths.
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
Attack Probability
0.00
0.25
0.50
0.75
1.00
Score
F1-score (fast detection)
F1-score (precise detection)
Similarity Score
METEOR Score
(a) English & Baidu Translator
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
Attack Probability
0.00
0.25
0.50
0.75
1.00
Score
F1-score (fast detection)
F1-score (precise detection)
Similarity Score
METEOR Score
(b) English & DeepL Translator
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
Attack Probability
0.00
0.25
0.50
0.75
1.00
Score
F1-score (fast detection)
F1-score (precise detection)
Similarity Score
METEOR Score
(c) Chinese & Baidu Translator
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
Attack Probability
0.00
0.25
0.50
0.75
1.00
Score
F1-score (fast detection)
F1-score (precise detection)
Similarity Score
METEOR Score
(d) Chinese & DeepL Translator
Figure 9: Robustness analysis of the watermark under re-
translation attacks. The x-axis represents the attack proba-
bility. The y-axis displays the F1-score, similarity score, and
METEOR score for both fast and precise detection modes.
Higher scores indicate better performance.
5.6
Robustness Analysis
We simulate two primary types of attacks that an attacker might
use to remove the watermark, specifically sentence-level attacks

Xi Yang, Kejiang Chen, Weiming Zhang, Chang Liu, Yuang Qi, Jie Zhang, Han Fang, and Nenghai Yu
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
Attack Probability
0.00
0.25
0.50
0.75
1.00
Score
F1-score (fast detection)
F1-score (precise detection)
Similarity Score
METEOR Score
(a) English
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
Attack Probability
0.00
0.25
0.50
0.75
1.00
Score
F1-score (fast detection)
F1-score (precise detection)
Similarity Score
METEOR Score
(b) Chinese
Figure 10: Robustness analysis of the watermark under pol-
ishing attacks.
(including re-translation and polishing) and word-level attacks (in-
cluding word deletion and synonym substitution). To illustrate the
impact of attacking varying proportions of text content, we set the
probability of each sentence or word being subjected to an attack.
Following this, we assess the watermark strength and the semantic
quality of the watermarked text under different attack probabilities.
Re-translation Attack. Considering a scenario in which attack-
ers attempt to re-translate portions of the watermarked text, we
calculate the F1-score (with the significance level 𝛼= 0.05), seman-
tic similarity score, and METEOR score of the watermarked text
under different attack probabilities. We employ two commercial
translation tools, namely Baidu Translator6 and DeepL Translator7
to perform the attack. For English text, we first translate it to Chi-
nese and then translate the resulting Chinese text back to English.
Conversely, for Chinese text, we first translate it to English and
then translate the resulting English text back to Chinese. As shown
in Figure 9, as the attack probability increases, more content within
the text is altered, resulting in a progressively weakened water-
mark. However, the METEOR scores follow a similar trend. This
suggests that when a large proportion of the text is modified, the
watermark will be weakened, but the attacked text also undergoes
significant structural and semantic changes compared to the orig-
inal text. This contradicts the attacker’s objective. Consequently,
when the attacker makes small-scale attacks on the text content, our
watermark demonstrates good robustness. For instance, when half
of the text undergoes a re-translation attack, the F1-score remains
above 0.75, still maintaining a reasonable level of robustness.
Polishing Attack. Polishing attacks on watermarked texts can be
carried out by attackers using top-notch LLM services. We employ
the API of GPT-3.5-turbo provided by OpenAI to perform this
type of attack. We calculate the F1-score (with 𝛼= 0.05), semantic
6https://fanyi.baidu.com/
7https://www.deepl.com/translator
0.1
0.2
0.3
0.4
0.5
Attack Probability
0.00
0.25
0.50
0.75
1.00
Score
F1-score (fast detection)
F1-score (precise detection)
Similarity Score
METEOR Score
(a) English
0.1
0.2
0.3
0.4
0.5
Attack Probability
0.00
0.25
0.50
0.75
1.00
Score
F1-score (fast detection)
F1-score (precise detection)
Similarity Score
METEOR Score
(b) Chinese
Figure 11: Robustness analysis of the watermark under word
deletion attacks.
similarity score, and METEOR score of the watermarked text under
different attack probabilities. The prompts we use for English and
Chinese text are: “Please polish the input text without changing
its meaning. The input text is: [watermarked text]” and “润色这
段话，不要改变原始语义。这段话的内容是: [watermarked
text]”, respectively. The results, shown in Figure 10, demonstrate
that GPT-3.5-based polishing causes more severe damage to the
watermark than re-translation. This is mainly because polishing
alters the text content to a greater extent than translation, and the
GPT-3.5 model may generate more associative content based on
the original content. However, this also leads to more significant
damage to the semantic quality of the original text, as indicated
by the METEOR score drop to around 0.5 when attacked with a
probability of 0.6, which indicates that the alignment between the
original text and the attacked text is significantly affected.
Word Deletion Attack. To test the robustness of our watermark
against word deletion attacks, we assign a deletion probability to
each word (including symbols) and evaluate the watermark strength
and text quality after the attack under different probabilities. As
shown in Figure 11, deletion attacks can severely damage the se-
mantics of the text, causing the text quality to decline sharply as the
attack probability (proportion of attacked content) increases. When
the deletion probability of each word is 0.5, nearly half of the text
content is deleted, making each sentence incomplete. As a result,
our watermark is almost completely erased, and the attacked text
also becomes unusable. However, when the removed content does
not exceed 30%, our watermark still maintains good detectability,
even if the original semantics have been severely compromised.
Synonym Substitution Attack. Synonym substitution can hap-
pen when users are unhappy with certain word choices and modify
them, or when attackers try to remove the watermark by changing
words. To perform synonym substitution attack while preserving

Watermarking Text Generated by Black-Box Language Models
0.1
0.2
0.3
0.4
0.5
Attack Probability
0.00
0.25
0.50
0.75
1.00
Score
F1-score (fast detection)
F1-score (precise detection)
Similarity Score
METEOR Score
(a) English
0.1
0.2
0.3
0.4
0.5
Attack Probability
0.00
0.25
0.50
0.75
1.00
Score
F1-score (fast detection)
F1-score (precise detection)
Similarity Score
METEOR Score
(b) Chinese
Figure 12: Robustness analysis of the watermark under syn-
onym substitution attacks.
text quality as much as possible, we use our own synonym gen-
eration algorithm from §4.2 and also do not modify words that
are unlikely to have high-quality synonyms. We set the probabil-
ity of each word being replaced by a synonym and evaluate the
watermark strength after the attack under different probabilities.
As shown in Figure 12, the F1-scores decrease as the probability
of synonym substitution increases. When each word is replaced
with a 0.5 probability, our watermark is almost completely erased.
This is because the synonym substitution process can be seen as a
watermark rewriting attack on our watermarked text, and when
half of the words are changed, all the binary encodings represented
by each word and its preceding word are rewritten.
The results under sentence-level and word-level attacks illustrate
that our watermark can be effectively preserved as long as the ma-
jority of watermark-bearing words are not modified. In other words,
our watermark can be linked to the semantics, making it hard for
attackers to completely remove the watermark while maintaining
the original text quality.
5.7
Time Cost of Fast and Precise Detection
Table 2 shows the average detection time per sample in both the fast
and precise detection modes. A sample of about 200 words or 200
Chinese characters takes around 0.01 seconds to detect in fast mode.
In precise detection, the average detection time is 7.646 seconds for
an English sample of 200 words and 5.094 seconds for a Chinese
sample of 200 characters, which has slightly less content than the
English samples. This indicates that the precise detection spends
more time analyzing text to enhance the detection capability.
5.8
Performance on Human Texts
Previous experiments are conducted on generated text. Since the
human brain’s language system can currently also be considered a
Table 2: Average detection time (seconds/sample) for English
and Chinese texts in both fast and precise detection modes.
We utilize a single NVIDIA GeForce RTX 2080 Ti GPU in the
precise detection.
Runtime
Fast Mode
Precise Mode
English
0.009
7.646
Chinese
0.011
5.094
Table 3: Comparison of watermarking methods under word
deletion attacks with different word deletion probabilities.
We utilize 𝑍-score (↑) to measure the watermark strength.
Attack
Ours
Yang et al. [39]
AWT [2]
Probability
Fast
Precise
0.1
3.00
3.63
2.19
2.73
0.2
2.50
2.96
1.42
2.46
black box model, we expand our investigation to encompass human-
written text, evaluating watermark strength under various 𝜏word
values, following the experimental setup in §5.2. We use the English
FakeNews8 and Chinese People’s Daily9 datasets, respectively. As
shown in Figure 13, watermark strength in human-written text is
similar to that observed in generated text, as presented in Figure 3.
Moreover, Figure 14 indicates that the watermarked human-written
text can maintain the original semantics. Therefore, our method
is not only applicable to generated text but also to human-written
text, thereby broadening its potential scope and utility.
5.9
Comparison with Traditional Multi-bit
Text Watermarking Methods
Traditional multi-bit text watermarking methods, as discussed in
§2.3, focus on embedding multiple bits of information for copyright
protection and leak tracing, which makes them difficult to compare
with our method directly. Therefore, we restructure these methods
to achieve the functionality of watermark detection. Specifically,
we set the embedded multi-bit watermark sequence to consist of
repeated bit-1s and employ the hypothesis test in our method to
examine the extracted bit sequence for watermark detection. Then,
we use the word deletion attack for robustness comparison (setting
the deletion probability to only 0.1 and 0.2, which is sufficient to
demonstrate the differences between these methods). As shown in
Table 3, the method proposed by Yang et al. [39] exhibits sensitivity
to contextual changes, resulting in a rapid decline in watermark
detection performance when a small portion of words is deleted.
Although AWT [2] can provide stronger robustness, it significantly
sacrifices semantic quality by introducing words or symbols that
disrupt the semantic structure of the text, as shown in Table 4. How-
ever, this severely compromises fidelity. In contrast, our method
strikes a balance between robustness and fidelity, maintaining the
original semantics without introducing grammatical errors while
also providing better watermark strength.
8https://www.kaggle.com/datasets/clmentbisaillon/fake-and-real-news-dataset
9https://www.kaggle.com/datasets/concyclics/renmindaily

Xi Yang, Kejiang Chen, Weiming Zhang, Chang Liu, Yuang Qi, Jie Zhang, Han Fang, and Nenghai Yu
0.0
0.2
0.4
0.6
0.8
1.0
False Positive Rate
0.0
0.2
0.4
0.6
0.8
1.0
True Positive Rate
word=0.7 (AUC = 1.00)
word=0.75 (AUC = 1.00)
word=0.8 (AUC = 0.96)
word=0.85 (AUC = 0.75)
(a) English & Fast Detection
0.0
0.2
0.4
0.6
0.8
1.0
False Positive Rate
0.0
0.2
0.4
0.6
0.8
1.0
True Positive Rate
word=0.7 (AUC = 1.00)
word=0.75 (AUC = 1.00)
word=0.8 (AUC = 0.99)
word=0.85 (AUC = 0.90)
(b) English & Precise Detection
0.0
0.2
0.4
0.6
0.8
1.0
False Positive Rate
0.0
0.2
0.4
0.6
0.8
1.0
True Positive Rate
word=0.7 (AUC = 1.00)
word=0.75 (AUC = 0.99)
word=0.8 (AUC = 0.88)
word=0.85 (AUC = 0.67)
(c) Chinese & Fast Detection
0.0
0.2
0.4
0.6
0.8
1.0
False Positive Rate
0.0
0.2
0.4
0.6
0.8
1.0
True Positive Rate
word=0.7 (AUC = 1.00)
word=0.75 (AUC = 1.00)
word=0.8 (AUC = 0.97)
word=0.85 (AUC = 0.86)
(d) Chinese & Precise Detection
Figure 13: ROC curves with AUC values for watermark detection in human-written text under different languages,𝜏word values,
and detection modes.
English
Similarity
Chinese
Similarity
English
METEOR
Chinese
METEOR
0.00
0.25
0.50
0.75
1.00
Score
word=0.7
word=0.75
word=0.8
word=0.85
Figure 14: Semantic similarity and METEOR scores of wa-
termarked human text compared to the original text under
different 𝜏word values.
Table 4: Examples of watermarked sentences compared with
AWT. The substituted words are underlined.
Original
AWT [2]
Ours
resulting in a population
decline as workers left for
other areas
resulting in a population
decline an workers left for
other areas
resulting in a population
dip as workers left for
other areas
but the complex is broken
up by the heat of cooking
and the complex is broken
up by the heat of cooking
but the complex is torn up
by the heat of cooking
For the second part of the
show, Carey had the sec-
ond costume change of
the evening, donning a
long <unk> black gown
and semi @-@ <unk>
hair.
For the second part of the
show, Carey had the sec-
ond Buddhist change of
the evening, were a long
<unk> black gown and
semi @-@ <unk> hair.
For the second part of the
program, Carey had the
second costume change
of the night, donning
a lengthy <unk> black
gown
and
semi
@-@
<unk> hair.
5.10
Ablation: Assessing the Roles of 𝜏sent and
𝜏word in Semantic Quality Control
We conduct ablation experiments on the semantic quality control
modules to demonstrate the necessity of each component. The
semantic control module comprises two parts: the sentence-level
semantic similarity and the word-level semantic similarity. The
sentence-level constraint requires the similarity score between
the watermarked and original text to exceed 𝜏sent. The word-level
constraint requires the weighted average of global and contextual
similarity between the word used for watermarking and the original
Table 5: Ablation study results showcasing the importance
of sentence-level and word-level semantic similarity con-
straints in maintaining the semantic quality of the water-
marked text during watermark injection.
Original
In the warm embrace of the golden sun, I stroll through the
vibrant garden, filled with the delightful aroma of blossom-
ing flowers. The lush green grass caressed my feet, ...
Watermarked
In the warm hug of the golden sun, I walk through the bril-
liant garden, full with the delightful aroma of blossoming
flowers. The lush green lawn caressed my feet, ...
Watermarked
w/o 𝜏sent
In the cool hug of the golden sun, I walk through the bril-
liant garden, filled with the delightful aroma of blossoming
flowers. The lush purple soil caressed my feet, ...
Watermarked
w/o 𝜏word
In the light embrace of the golden sunshine, I walk through
the flower yard, full with the delightful aroma of blossoming
petal. The lush grass grass caressed my shoe, ...
word to exceed 𝜏word. Table 5 shows that, without the sentence-
level constraint, the original words may be replaced by statistically
similar words that express different or opposite semantics (e.g.,
‘warm’-‘cool’, ‘green’ -‘purple’, and ‘grass’-‘soil’). In the absence of
the word-level constraint, low-quality, irrelevant, or grammatically
erroneous words are introduced (e.g., ‘green grass’-‘grass grass’).
Only with 𝜏sent and 𝜏word together can we ensure the semantic
quality of the watermarked text.
6
DISCUSSION
Comparison with the Watermarking Method for White-Box
Language Models. The watermarking method proposed by Kirchen-
bauer et al. [12] is intended for model owners and requires the
control to the model’s output probability distribution. This char-
acteristic makes it infeasible in black-box language model usage
scenarios where the probability distribution information is not avail-
able. Unlike the white-box method that generates watermarked text
from scratch, our method modifies the already generated text and
can maintain the original semantics, form, and style. We contend
that these two methods are more complementary than competitive.
If needed, black-box watermarking, white-box watermarking, and
passive detection techniques can be combined to offer multiple de-
tection results for achieving high robustness. OpenAI also pointed

Watermarking Text Generated by Black-Box Language Models
out that the company was researching watermarking as a form of
detection, and that it could complement the passive detection tool.
Reasons to Use BERT for Synonym Generation. The use of
BERT models is attributed to their superior synonym generation
performance among open-source models. It should be emphasized
that our main goal is to propose a general framework for water-
marking text generated by black-box language models. The specific
algorithms within the framework are adaptable. As more efficient
synonym generation algorithms emerge in the future, they can be
readily incorporated into our framework.
7
CONCLUSION
In this paper, we propose a watermarking framework for injecting
authentication watermarks into text generated from black-box lan-
guage models. The motivation is to enable third-parties who employ
black-box language model services (e.g., APIs) to autonomously in-
ject watermarks in their generated text for the purposes of detection
and authentication. Extensive experiments on text datasets with
different languages and topics (Generality) have demonstrated
that the watermark retains a connection to the original semantics
(Fidelity), making it challenging for adversaries to remove the
watermark without affecting the integrity of the original content
(Robustness). We hope our method can provide new insights for
generated text detection and inspire more future work.

Xi Yang, Kejiang Chen, Weiming Zhang, Chang Liu, Yuang Qi, Jie Zhang, Han Fang, and Nenghai Yu
REFERENCES
[1] 2023. ZeroGPT. https://www.zerogpt.com
[2] Sahar Abdelnabi and Mario Fritz. 2021. Adversarial watermarking transformer:
Towards tracing text provenance with data hiding. In 2021 IEEE Symposium on
Security and Privacy (SP). IEEE, 121–140.
[3] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan,
Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda
Askell, et al. 2020. Language models are few-shot learners. Advances in neural
information processing systems 33 (2020), 1877–1901.
[4] Michael Denkowski and Alon Lavie. 2014. Meteor universal: Language spe-
cific translation evaluation for any target language. In Proceedings of the ninth
workshop on statistical machine translation. 376–380.
[5] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. Bert:
Pre-training of deep bidirectional transformers for language understanding. arXiv
preprint arXiv:1810.04805 (2018).
[6] Yogesh K Dwivedi, Nir Kshetri, Laurie Hughes, Emma Louise Slade, Anand Je-
yaraj, Arpan Kumar Kar, Abdullah M Baabdullah, Alex Koohang, Vishnupriya
Raghavan, Manju Ahuja, et al. 2023. “So what if ChatGPT wrote it?” Multidisci-
plinary perspectives on opportunities, challenges and implications of generative
conversational AI for research, practice and policy. International Journal of
Information Management 71 (2023), 102642.
[7] N Editorials. 2023. Tools such as ChatGPT threaten transparent science; here are
our ground rules for their use. Nature 613 (2023), 612.
[8] Merran Evans, Nicholas Hastings, Brian Peacock, and Catherine Forbes. 2011.
Statistical distributions. John Wiley & Sons.
[9] The Guardian. 2023. A fake news frenzy: why ChatGPT could be disastrous for
truth in journalism. https://www.theguardian.com/commentisfree/2023/mar/03/
fake-news-chatgpt-truth-journalism-disinformation.
[10] Biyang Guo, Xin Zhang, Ziyuan Wang, Minqi Jiang, Jinran Nie, Yuxuan Ding,
Jianwei Yue, and Yupeng Wu. 2023. How Close is ChatGPT to Human Experts?
Comparison Corpus, Evaluation, and Detection. arXiv preprint arXiv:2301.07597
(2023).
[11] Di Jin, Zhijing Jin, Joey Tianyi Zhou, and Peter Szolovits. 2020. Is bert really
robust? a strong baseline for natural language attack on text classification and
entailment. In Proceedings of the AAAI conference on artificial intelligence, Vol. 34.
8018–8025.
[12] John Kirchenbauer, Jonas Geiping, Yuxin Wen, Jonathan Katz, Ian Miers, and
Tom Goldstein. 2023. A watermark for large language models. arXiv preprint
arXiv:2301.10226 (2023).
[13] Shen Li, Zhe Zhao, Renfen Hu, Wensi Li, Tao Liu, and Xiaoyong Du. 2018. Ana-
logical Reasoning on Chinese Morphological and Semantic Relations. In Proceed-
ings of the 56th Annual Meeting of the Association for Computational Linguistics
(Volume 2: Short Papers) (Melbourne, Australia). Association for Computational
Linguistics, 138–143.
[14] Weixin Liang, Mert Yuksekgonul, Yining Mao, Eric Wu, and James Y. Zou. 2023.
GPT detectors are biased against non-native English writers. arXiv preprint
arXiv:2304.02819 (2023).
[15] Michael Liebrenz, Roman Schleifer, Anna Buadze, Dinesh Bhugra, and Alexander
Smith. 2023. Generating scholarly content with ChatGPT: ethical challenges for
medical publishing. The Lancet Digital Health 5, 3 (2023), e105–e106.
[16] Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer
Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019. Roberta: A
robustly optimized bert pretraining approach. arXiv preprint arXiv:1907.11692
(2019).
[17] Cade Metz. 2023. OpenAI CEO Sam Altman: AI will reshape society, acknowledges
risks. https://abcnews.go.com/Technology/openai-ceo-sam-altman-ai-reshape-
society-acknowledges/story?id=97897122
[18] Eric Mitchell, Yoonho Lee, Alexander Khazatsky, Christopher D Manning, and
Chelsea Finn. 2023. Detectgpt: Zero-shot machine-generated text detection using
probability curvature. arXiv preprint arXiv:2301.11305 (2023).
[19] BBC News. 2023. ChatGPT banned in Italy over privacy concerns. https://www.
bbc.com/news/technology-65139406.
[20] NBC News. 2023. ChatGPT banned from New York City public schools’ de-
vices and networks. https://www.nbcnews.com/tech/tech-news/new-york-city-
public-schools-ban-chatgpt-devices-networks-rcna64446.
[21] Cyberspace Administration of China. 2023. Draft Measures for the Management
of Generative Artificial Intelligence Services. http://www.cac.gov.cn/2023-04/11/
c_1682854275475410.htm.
[22] Council of the EU. 2023. Artificial Intelligence Act: Council calls for promoting
safe AI that respects fundamental rights. https://www.consilium.europa.eu/
en/press/press-releases/2022/12/06/artificial-intelligence-act-council-calls-for-
promoting-safe-ai-that-respects-fundamental-rights/.
[23] OpenAI. 2022. Introducing ChatGPT. https://openai.com/blog/chatgpt
[24] OpenAI. 2023. GPT-4 Technical Report. ArXiv abs/2303.08774 (2023).
[25] OpenAI. 2023. New AI classifier for indicating AI-written text. https://openai.
com/blog/new-ai-classifier-for-indicating-ai-written-text
[26] Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela
Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. 2022.
Training language models to follow instructions with human feedback. Advances
in Neural Information Processing Systems 35 (2022), 27730–27744.
[27] Jeffrey Pennington, Richard Socher, and Christopher D Manning. 2014. Glove:
Global vectors for word representation. In Proceedings of the 2014 conference on
empirical methods in natural language processing (EMNLP). 1532–1543.
[28] Jiameng Pu, Zain Sarwar, Sifat Muhammad Abdullah, Abdullah Rehman, Yoonjin
Kim, Parantapa Bhattacharya, Mobin Javed, and Bimal Viswanath. 2022. Deepfake
Text Detection: Limitations and Opportunities. arXiv preprint arXiv:2210.09421
(2022).
[29] Jiameng Pu, Zain Sarwar, Sifat Muhammad Abdullah, Abdullah Rehman, Yoonjin
Kim, Parantapa Bhattacharya, Mobin Javed, and Bimal Viswanath. 2022. Deepfake
Text Detection: Limitations and Opportunities. arXiv preprint arXiv:2210.09421
(2022).
[30] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever,
et al. 2019. Language models are unsupervised multitask learners. OpenAI blog
1, 8 (2019), 9.
[31] Chris Stokel-Walker. 2022. AI bot ChatGPT writes smart essays - should profes-
sors worry? Nature (2022).
[32] Jianlin Su. 2020. WoBERT: Word-based Chinese BERT model - ZhuiyiAI. Technical
Report. https://github.com/ZhuiyiTechnology/WoBERT
[33] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne
Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal
Azhar, et al. 2023. Llama: Open and efficient foundation language models. arXiv
preprint arXiv:2302.13971 (2023).
[34] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all
you need. Advances in neural information processing systems 30 (2017).
[35] Patrick von Platen. 2020. How to generate text: using different decoding methods
for language generation with Transformers. https://huggingface.co/blog/how-to-
generate
[36] Takashi Wada, Timothy Baldwin, Yuji Matsumoto, and Jey Han Lau. 2022. Unsu-
pervised Lexical Substitution with Decontextualised Embeddings. arXiv preprint
arXiv:2209.08236 (2022).
[37] Adina Williams, Nikita Nangia, and Samuel Bowman. 2018. A Broad-Coverage
Challenge Corpus for Sentence Understanding through Inference. In Proceedings
of the 2018 Conference of the North American Chapter of the Association for Com-
putational Linguistics: Human Language Technologies, Volume 1 (Long Papers).
Association for Computational Linguistics, 1112–1122.
[38] Max Wolff and Stuart Wolff. 2020. Attacking neural text detectors. arXiv preprint
arXiv:2002.11768 (2020).
[39] Xi Yang, Jie Zhang, Kejiang Chen, Weiming Zhang, Zehua Ma, Feng Wang, and
Nenghai Yu. 2022. Tracing text provenance via context-aware lexical substitution.
In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 36. 11613–
11621.
[40] GPT Zero. 2023. https://gptzero.me/.
[41] Jiaxing Zhang, Ruyi Gan, Junjie Wang, Yuxiang Zhang, Lin Zhang, Ping Yang,
Xinyu Gao, Ziwei Wu, Xiaoqun Dong, Junqing He, Jianheng Zhuo, Qi Yang,
Yongfeng Huang, Xiayu Li, Yanghan Wu, Junyu Lu, Xinyu Zhu, Weifeng Chen,
Ting Han, Kunhao Pan, Rui Wang, Hao Wang, Xiaojun Wu, Zhongshen Zeng,
and Chongpei Chen. 2022. Fengshenbang 1.0: Being the Foundation of Chinese
Cognitive Intelligence. CoRR abs/2209.02970 (2022).
[42] Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou,
Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, et al. 2023. A Survey
of Large Language Models. arXiv preprint arXiv:2303.18223 (2023).
[43] Wangchunshu Zhou, Tao Ge, Ke Xu, Furu Wei, and Ming Zhou. 2019. BERT-based
lexical substitution. In Proceedings of the 57th Annual Meeting of the Association
for Computational Linguistics. 3368–3373.

Watermarking Text Generated by Black-Box Language Models
A
RUNTIME OPTIMIZATION
In this paper, the watermark injection and detection algorithms
are presented in a sequential iterative manner for selected words
to facilitate easy understanding. However, in real-world engineer-
ing applications, this may lead to increased runtime. To expedite
the watermark injection and detection process, we can implement
parallel processing on multiple words in the given text, since the
original text is known. We first compute the POS for each word
in the text and record the index positions of words meeting the
POS criteria in an index list. Then, we employ BERT to generate
synonym candidates for all words with positions in the list. For
each candidate, we substitute it in the corresponding position of
the original text to create a new text variant. Once all candidate
texts are generated, we utilize batch processing to compute the sim-
ilarity scores for each candidate word simultaneously, significantly
reducing time for both watermark injection and precise detection.
Finally, we further refine the candidates based on their similarity
scores and choose the best synonyms for watermark injection using
our synonym sampling algorithm. Both the iterative and parallel
algorithms will be included in the released code.
B
DEMO AND SOURCE CODE
In the additional materials, we provide a demo for watermark in-
jection and detection based on Gradio10, including both the source
code and a demonstration video. The watermark carried in the ab-
stract can be detected by the detector in the demo, with a confidence
level of 98.52%, as shown in Figure 15.
C
PSEUDOCODE FOR THE ATTACKS
We provide further details related to the attacks used in our robust-
ness analysis. The process of re-translation attack is illustrated in
Algorithm 3, where we utilize the commercial Baidu Translation
API and DeepL API as translators. The process of polishing attack is
illustrated in Algorithm 4, where we employ GPT-3.5-turbo API11
to perform sentence polishing. In the same manner, the pseudocode
for word deletion and synonym substitution attacks can be found
in Algorithm 5 and Algorithm 6, respectively.
D
MORE EXAMPLES
In the additional materials, we provide text files (refer to english_sa
mples.txt and chinese_samples.txt) containing the original and
watermark texts utilized in our experiments, comprising 800 sam-
ples each for both Chinese and English. We set 𝜏𝑤𝑜𝑟𝑑= 0.8 for
English text and 𝜏𝑤𝑜𝑟𝑑= 0.75 for Chinese text.
10https://gradio.app/
11https://platform.openai.com/docs/models/gpt-3-5

Xi Yang, Kejiang Chen, Weiming Zhang, Chang Liu, Yuang Qi, Jie Zhang, Han Fang, and Nenghai Yu
Figure 15: Screenshot of using our demo to perform watermark detection on the abstract of this paper.
Algorithm 3 Re-translation Attack
Input: 𝑤𝑎𝑡𝑒𝑟𝑚𝑎𝑟𝑘𝑒𝑑_𝑡𝑒𝑥𝑡, the attack probability 𝑝
Output: 𝑎𝑡𝑡𝑎𝑐𝑘𝑒𝑑_𝑡𝑒𝑥𝑡
1: 𝑠𝑟𝑐←"ENG" or "CN"
2: if 𝑠𝑟𝑐== "ENG" then
3:
𝑖𝑛𝑡𝑒𝑟←"CN"
4: else
5:
𝑖𝑛𝑡𝑒𝑟←"ENG"
6: for each 𝑠𝑒𝑛𝑡in 𝑤𝑎𝑡𝑒𝑟𝑚𝑎𝑟𝑘𝑒𝑑_𝑡𝑒𝑥𝑡do
7:
𝑟𝑎𝑛𝑑_𝑛𝑢𝑚←𝑟𝑎𝑛𝑑𝑜𝑚(0, 1)
8:
if 𝑟𝑎𝑛𝑑_𝑛𝑢𝑚<= 𝑝then
9:
𝑡𝑟𝑎𝑛𝑠_𝑠𝑒𝑛𝑡←𝑡𝑟𝑎𝑛𝑠𝑙𝑎𝑡𝑜𝑟(𝑠𝑒𝑛𝑡,𝑠𝑟𝑐,𝑖𝑛𝑡𝑒𝑟)
10:
𝑟𝑒𝑡𝑟𝑎𝑛𝑠_𝑠𝑒𝑛𝑡←𝑡𝑟𝑎𝑛𝑠𝑙𝑎𝑡𝑜𝑟(𝑡𝑟𝑎𝑛𝑠_𝑠𝑒𝑛𝑡,𝑖𝑛𝑡𝑒𝑟,𝑠𝑟𝑐)
11: 𝑎𝑡𝑡𝑎𝑐𝑘𝑒𝑑_𝑡𝑒𝑥𝑡←concatenated sentences
Algorithm 4 Polishing Attack
Input: 𝑤𝑎𝑡𝑒𝑟𝑚𝑎𝑟𝑘𝑒𝑑_𝑡𝑒𝑥𝑡, 𝑝𝑟𝑜𝑚𝑝𝑡, the attack probability 𝑝
Output: 𝑎𝑡𝑡𝑎𝑐𝑘𝑒𝑑_𝑡𝑒𝑥𝑡
1: for each 𝑠𝑒𝑛𝑡in 𝑤𝑎𝑡𝑒𝑟𝑚𝑎𝑟𝑘𝑒𝑑_𝑡𝑒𝑥𝑡do
2:
𝑟𝑎𝑛𝑑_𝑛𝑢𝑚←𝑟𝑎𝑛𝑑𝑜𝑚(0, 1)
3:
if 𝑟𝑎𝑛𝑑_𝑛𝑢𝑚<= 𝑝then
4:
𝑝𝑜𝑙𝑖𝑠ℎ𝑒𝑑_𝑠𝑒𝑛𝑡←GPT-3.5-turbo(𝑝𝑟𝑜𝑚𝑝𝑡,𝑠𝑒𝑛𝑡)
5: 𝑎𝑡𝑡𝑎𝑐𝑘𝑒𝑑_𝑡𝑒𝑥𝑡←concatenated sentences
Algorithm 5 Word Deletion Attack
Input: 𝑤𝑎𝑡𝑒𝑟𝑚𝑎𝑟𝑘𝑒𝑑_𝑡𝑒𝑥𝑡, the attack probability 𝑝
Output: 𝑎𝑡𝑡𝑎𝑐𝑘𝑒𝑑_𝑡𝑒𝑥𝑡
1: 𝑠𝑒𝑛𝑡𝑒𝑛𝑐𝑒𝑠←split 𝑤𝑎𝑡𝑒𝑟𝑚𝑎𝑟𝑘𝑒𝑑_𝑡𝑒𝑥𝑡into sentences
2: for each 𝑠𝑒𝑛𝑡in 𝑠𝑒𝑛𝑡𝑒𝑛𝑐𝑒𝑠do
3:
𝑤𝑜𝑟𝑑𝑠←split 𝑠𝑒𝑛𝑡into words (including symbols)
4:
for each 𝑤𝑜𝑟𝑑in 𝑤𝑜𝑟𝑑𝑠do
5:
𝑟𝑎𝑛𝑑_𝑛𝑢𝑚←𝑟𝑎𝑛𝑑𝑜𝑚(0, 1)
6:
if 𝑟𝑎𝑛𝑑_𝑛𝑢𝑚<= 𝑝then
7:
remove 𝑤𝑜𝑟𝑑from 𝑠𝑒𝑛𝑡
8: 𝑎𝑡𝑡𝑎𝑐𝑘𝑒𝑑_𝑡𝑒𝑥𝑡←concatenated words
Algorithm 6 Synonym Substitution Attack
Input: 𝑤𝑎𝑡𝑒𝑟𝑚𝑎𝑟𝑘𝑒𝑑_𝑡𝑒𝑥𝑡, 𝑝
Output: 𝑎𝑡𝑡𝑎𝑐𝑘𝑒𝑑_𝑡𝑒𝑥𝑡
1: 𝑠𝑒𝑛𝑡𝑒𝑛𝑐𝑒𝑠←split 𝑤𝑎𝑡𝑒𝑟𝑚𝑎𝑟𝑘𝑒𝑑_𝑡𝑒𝑥𝑡into sentences
2: for each 𝑠𝑒𝑛𝑡in 𝑠𝑒𝑛𝑡𝑒𝑛𝑐𝑒𝑠do
3:
𝑤𝑜𝑟𝑑𝑠←split 𝑠𝑒𝑛𝑡into words
4:
for each 𝑤𝑜𝑟𝑑in 𝑤𝑜𝑟𝑑𝑠do
5:
if POSFilter(𝑤𝑜𝑟𝑑) then
⊲Alg. 1
6:
𝑟𝑎𝑛𝑑_𝑛𝑢𝑚←𝑟𝑎𝑛𝑑𝑜𝑚(0, 1)
7:
if 𝑟𝑎𝑛𝑑_𝑛𝑢𝑚<= 𝑝then
8:
𝐶←SynonymsGen(𝑠𝑒𝑛𝑡, 𝑤𝑜𝑟𝑑)
⊲Alg. 1
9:
𝐶′ ←FilterCandidates(𝑠𝑒𝑛𝑡, 𝐶, 𝑤𝑜𝑟𝑑)
⊲Alg. 1
10:
if 𝐶′ ≠∅then
11:
Substitute 𝑤𝑜𝑟𝑑with the first word in 𝐶′
12: 𝑎𝑡𝑡𝑎𝑐𝑘𝑒𝑑_𝑡𝑒𝑥𝑡←concatenated sentences
