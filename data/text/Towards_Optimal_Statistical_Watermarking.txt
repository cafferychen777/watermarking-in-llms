Towards Optimal Statistical Watermarking
Baihe Huang*
Hanlin Zhuâ€ 
Banghua Zhuâ€¡
Kannan Ramchandran Â§
Michael I. JordanÂ¶
Jason D. Lee||
Jiantao Jiao**
Abstract
We study statistical watermarking by formulating it as a hypothesis testing problem,
a general framework which subsumes all previous statistical watermarking methods.
Key to our formulation is a coupling of the output tokens and the rejection region,
realized by pseudo-random generators in practice, that allows non-trivial trade-offs
between the Type I error and Type II error. We characterize the Uniformly Most
Powerful (UMP) watermark in the general hypothesis testing setting and the minimax
Type II error in the model-agnostic setting. In the common scenario where the output
is a sequence of n tokens, we establish nearly matching upper and lower bounds on
the number of i.i.d. tokens required to guarantee small Type I and Type II errors. Our
rate of Î˜(hâˆ’1 log(1/h)) with respect to the average entropy per token h highlights
potentials for improvement from the rate of hâˆ’2 in the previous works. Moreover,
we formulate the robust watermarking problem where the user is allowed to perform
a class of perturbations on the generated texts, and characterize the optimal Type
II error of robust UMP tests via a linear programming problem. To the best of our
knowledge, this is the first systematic statistical treatment on the watermarking problem
with near-optimal rates in the i.i.d. setting, which might be of interest for future works.
1
Introduction
The prevalence of large language models (LLMs) in recent years makes it challenging and
important to detect whether a human-like text is produced by the LLM system (Kirchenbauer
et al., 2023a; Kuditipudi et al., 2023; Christ et al., 2023; Yoo et al., 2023; Fernandez et al.,
*baihe_huang@berkeley.edu. University of California, Berkeley.
â€ hanlinzhu@berkeley.edu. University of California, Berkeley.
â€¡banghua@berkeley.edu. University of California, Berkeley.
Â§kannanr@berkeley.edu. University of California, Berkeley.
Â¶jordan@cs.berkeley.edu. University of California, Berkeley.
||jasonlee@princeton.edu. Princeton University.
**jiantao@eecs.berkeley.edu. University of California, Berkeley.
1
arXiv:2312.07930v3  [cs.LG]  6 Feb 2024

2023; Fu et al., 2023; Wang et al., 2023; Yang et al., 2023; Liu et al., 2023; Zhao et al.,
2023; Koike et al., 2023). On the one hand, some of the most advanced LLMs to date,
such as GPT-4 (OpenAI, 2023a), are good at producing human-like texts, which might
be hard to distinguish from human-generated texts even for humans in various scenarios.
On the other hand, it is important to keep human-produced text datasets separated from
machine-produced texts in order to avoid the spread of misleading information (Vincent,
2022) and the contamination of training datasets for future language models (Kuditipudi
et al., 2023).
To detect machine-generated content, a recent line of work (Kirchenbauer et al., 2023a;
Kuditipudi et al., 2023; Christ et al., 2023) proposes to inject statistical watermarks, a signal
embedded within the generated texts which reveals the generation source, into texts. As
discussed in Kuditipudi et al. (2023), there are three desirable properties of watermarking:
1. distortion-free: the watermark should not alert the distribution of the generated texts;
2. agnostic: the detector should not know the language model or the prompt; 3. robust:
the detector should be able to detect the watermark even under slight perturbation of the
generated texts. However, previously proposed methods are either heuristic or guaranteed
by different, sub-optimal mathematical descriptions of the above properties, making it
difficult to systematically evaluate the watermarking schemes and to draw useful statistical
conclusions.
Motivated by this, we propose a unifying formulation of statistical watermarking based
on hypothesis testing, and study the trade-off between the Type I error and the Type II error.
More specifically, our contributions are summarized as follows:
â€¢ We formulate statistical watermarking as a hypothesis testing problem with a random
rejection region, and specify model-agnostic watermarking, where the distribution of
the rejection region is independent of the underlying model distribution, as a notion
highly practical in real-world applications.
â€¢ We find the optimal Type II error among all level-Î± tests and explicitly characterize
the most powerful watermarking scheme that achieves it. For model-agnostic water-
marking, we construct the optimal distribution of the reject region and establish the
minimax increase in Type II error in comparison to the most powerful watermarking
schemes.
â€¢ In the context where the sample is a sequence of many i.i.d. tokens, we provide
nearly-matching upper and lower bounds for the minimum number of tokens required
to guarantee small type I and type II errors. Our rate hâˆ’1 log(1/h) improves upon
previous works featuring a rate of hâˆ’2, in terms of h â€” the average entropy of per
generated tokens.
â€¢ Additionally, we formulate a robust watermarking problem where the watermarking
scheme is robust to a class of perturbations that the user can employ to the outputs. In
this setting, we also characterize the optimal type II error and the construction of the
robust watermarking scheme via a linear program.
2

1.1
Related works
Watermarking is a powerful white-box method for detecting LLM-generated texts (Tang
et al., 2023). Watermarks can be injected either into a pre-existing text (edit-based water-
marks) or during the text generation (generative watermarks). Our work falls in the latter
category. Edit-based watermarking (Rizzo et al., 2019; Abdelnabi & Fritz, 2021; Yang
et al., 2022; Kamaruddin et al., 2018) has been the focus of several studies in the past. The
concept of generative watermarking dates back to the work of Venugopal et al. (2011), while
our work is more relevant to a recent line of works (Aaronson, 2022a; Kirchenbauer et al.,
2023a; Kuditipudi et al., 2023; Christ et al., 2023) that introduce statistical signals into text
generation. Specifically, Kirchenbauer et al. (2023a) increases the probability that tokens
are chosen from a randomly sampled â€˜greenâ€™ list; Aaronson (2022a) selects the token i that
maximizes keys randomly sampled from exponential distributions with mean 1/pi; Christ
et al. (2023) samples the tokens by solving the optimal transport from uniform distribution
in [0, 1]; Kuditipudi et al. (2023) introduces inverse transform sampling as a distortion-free
watermarking method; Zhao et al. (2023) proposes a simplified variation of Kirchenbauer
et al. (2023a) where a fixed Green-Red split is used consistently. These watermarks are
evaluated in the benchmark of Piet et al. (2023).
Statistical watermarking techniques share the similarity that the outputs are correlated
with some secret keys (which could come from either external randomness or internal
hashing), thereby coupling the rejection region and the outputs in the hypothesis testing.
This fact is recognized by recent works of Kuditipudi et al. (2023); Zhao et al. (2023), where
model-agnosticism in the detection phase is also emphasized. The exponential scheme
in Aaronson (2022b), the inverse transform sampling scheme in Kuditipudi et al. (2023),
and the binary scheme in Christ et al. (2023) come with theoretical guarantees that (i)
the watermarked model distribution cannot be distinguished from the original distribution
(called undetectability (Christ et al., 2023) or distortion-freeness (Kuditipudi et al., 2023)),
and (ii) the outputs from the watermarked models are statistically detectable as long as the
entropy is lower bounded. In contrast, Kirchenbauer et al. (2023a) is not distortion-free,
nonetheless enjoying little degradation in generation quality and provable detectability (Zhao
et al., 2023) with suitable parameter choice of the bias parameter (logits increase Î´ in the
â€˜greenâ€™ list). Despite the aforementioned theoretical efforts in establishing guarantees for
existing watermarks, the fundamental tradeoff in this hypothesis testing problem and the
rates on the required number of generated tokens remain unsolved.
Watermarks can also be injected with private forgeability and public verifiability (Fairoze
et al., 2023), hence functioning effectively as digital signatures. Meanwhile, various attack
algorithms against watermarking schemes were also studied (Kirchenbauer et al., 2023a,b;
Sato et al., 2023; Zhang et al., 2023; Kuditipudi et al., 2023). These attacking schemes
apply quality-preserving perturbations to the watermarked outputs in delicate ways, and
are therefore modelled by the perturbation graph (Definition 4.1) in the robust watermark
framework in Section 4. With the success of various attacking methods, robustness becomes
an important consideration in watermarking techniques. However, Zhang et al. (2023)
3

proves that it is only feasible to achieve robustness to a well-specified set of attacks, instead
of all. This fact aligns with our Theorem 4.4, which characterizes the fundamental limits of
robust watermarking under different attacking powers.
1.2
Notation
Define (x)+ := max{x, 0}, x âˆ§y := min{x, y}, x âˆ¨y = max{x, y}. For any set A, we
write Ac as the complement of set A, |A| as its cardinality, and 2A := {B : B âŠ‚A} as the
power set of A. We use notations g(n) = O (f(n)), g(n) = â„¦(f(n)), and g(n) = Î˜ (f(n))
to denote that there exists numerical constants C1, c2, C3, c4 such that for all n > 0: g(n) â‰¤
C1 Â· f(n), g(n) â‰¥c2 Â· f(n), and c4 Â· f(n) â‰¤g(n) â‰¤C3 Â· f(n), respectively. Throughout,
we use ln to denote natural logarithm.
The total variation (TV) distance between two probability measures Âµ, Î½ is denoted
by TV(Âµâˆ¥Î½). We use supp(Âµ) to denote the support of a probability measure Ï. Given a
sample space â„¦, let âˆ†(â„¦) denote the set of all probability measures over â„¦(take the discrete
Ïƒ-algebra). We write Î´x as the Dirac measure on x, i.e., Î´x(A) =
(
1,
x âˆˆA
0,
x /âˆˆA. A coupling
for two distributions (i.e. probability measures) is a joint distribution of them.
2
Watermarking as a Hypothesis Testing Problem
In the problem of statistical watermarking, a service provider (e.g., a language model
system), who possesses a distribution Ï over a sample space â„¦, aims to make the samples
from the service provider distinguishable by a detector, without changing Ï. The service
provider achieves this by sharing a watermark key (generated from a distribution that is
coupled with Ï) with the detector, with the goal of controlling both the Type I error (an
independent output is falsely detected as from Ï) and the Type II error (an output from Ï
fails to be detected). This random key together with the detection rule constitute a (random)
rejection region. In the following, we formulate this problem as hypothesis testing with
random rejection regions.
Problem 2.1 (Watermarking). Fix Ïµ â‰¥0. Given a probability measure Ï over sample
space â„¦1, an Ïµ-distorted watermarking scheme of Ï is a probability measure P (a joint
probability of the output X and the rejection region R) over the sample space â„¦âŠ—2â„¦such
that TV(P(Â·, 2â„¦)âˆ¥Ï) â‰¤Ïµ, where P(Â·, 2â„¦) is the marginal probability of X over â„¦. In the
generation phase, the service provider samples (X, R) from P, provides the output X to the
service user, and sends the rejection region R to the detector.
In the detection phase, a detector is given a tuple (X, R) âˆˆâ„¦âŠ—2â„¦where X is sampled
from an unknown distribution and R, given by the service provider, is sampled from the
1Throughout we will assume that â„¦is discrete, as in most applications.
4

marginal probability P(â„¦, Â·) over 2â„¦. The detector is tasked with using R to conduct a
hypothesis test that involves two competing hypotheses:
H0 : X is sampled independently from R,
versus H1 : (X, R) is sampled from the joint distribution P.
The Type I error of P, defined as Î±(P) := supÏ€âˆˆâˆ†(â„¦) PY âˆ¼Ï€,(X,R)âˆ¼P(Y âˆˆR), is the maxi-
mum probability that an independent sample Y is falsely rejected. The Type II error of P,
defined as Î²(P) := P(X,R)âˆ¼P(X /âˆˆR), is the probability that the sample (X, R) from the
joint probability P is not detected.
1
2
Detector f
 f(
1 
reject
) =
 f(
2 
accept
) =
Detection 
Phase
Generation 
Phase
Watermarked Model
Any Other Model
Figure 1: Illustration of watermarking in practice.
A few remarks are in order.
Remark 2.2 (Difference between
classical hypothesis testing). In
classical hypothesis testing, the re-
jection region is often nonrandom-
ized or independent from the test
statistics. However, in watermark-
ing problem, the service provider
has the incentive to facilitate the
detection. The key insight is that
P is a coupling of the random out-
put X and the random rejection
region R, so that X âˆˆR occurs
with a high probability (low Type
II error), while any independent
sample Y lies in R with a low prob-
ability (low Type I error).
Remark 2.3 (Implementation). In fact, it is imperative for the detector to observe the
rejection region that is coupled with the output: otherwise, the output from the service
provider and another independent output from the same marginal distribution would be
statistically indistinguishable.
In practice, the process of coupling and sending the rejection region can be implemented
by cryptographical techniques: the service provider could hash a secret key sk, and use
pseudo-random functions F1, F2 to generate (X, R) = (F1(sk), F2(sk)). Now it suffices
to send the secret key to the detector, who can then reproduce the reject region using the
pseudo-random function F2. This process is illustrated in Figure 1.
By introducing the coupled and random rejection region, we abstract away the minutiae
of cryptographical implementations, therefore allowing us to focus solely on the statistical
trade-offs.
For practical applications, it is additionally desirable for watermarking schemes to be
model-agnostic, i.e, the marginal distribution of the rejection region is irrelevant to the
5

watermarked distribution. Recall from Remark 2.3 that in practice, detectors usually adopt
a pseudo-random function to generate the reject region from the shared secret keys. If the
watermarking scheme P depends on the underlying distribution Ï, then the pseudo-random
function, and effectively the detector, need to know Ï. On the other hand, model-agnostic
watermarking enables the detector to use a fixed, pre-determined pseudo-random function
to generate the reject region, and hence perform hypothesis-testing without the knowledge
of the underlying model that generates the output. This is an important property enjoyed
by existing watermarks (Aaronson, 2022b; Kirchenbauer et al., 2023a; Christ et al., 2023;
Kuditipudi et al., 2023). Therefore in the following, we formulate model-agnostic within
our hypothesis testing framework.
Problem 2.4 (Model-Agnostic Watermarking). Given a sample space â„¦and a set Q âŠ‚âˆ†(â„¦),
a Q-watermarking scheme is a tuple (Î·, {PÏ}ÏâˆˆQ) where Î· is a probability measure over 2â„¦,
such that for any probability measure Ï âˆˆQ, PÏ is a distortion-free watermarking scheme
of Ï and its marginal distribution over 2â„¦, PÏ(â„¦, Â·), equals Î·(Â·).
A model-agnostic watermarking scheme is a âˆ†(â„¦)-watermarking scheme.
Remark 2.5 (Information of the model). A Q-watermarking scheme can be interpreted as a
way to watermark all distributions in the set Q while revealing no information of the model
used to generate the output other than the membership inside Q (i.e., observing the rejection
region, one is only able to infer that the output comes from a model in Q, but is unable to
know which exactly the model is). By letting Q be âˆ†(â„¦), model-agnostic watermarking thus
reveals no information of the model.
2.1
Examples
In the following examples, we show how existing watermarking schemes fit in our frame-
work.
Example 2.6 (Text Generation with Soft Red List, Kirchenbauer et al. (2023a)). In Al-
gorithm 2 of Kirchenbauer et al. (2023a), the watermarking scheme (over sample space
â„¦= V âˆ—where V is the â€˜vocabularyâ€™, i.e., the set of all tokens) of Ï is given as follows:
â€¢ Fix threshold C âˆˆR, green list size Î³ âˆˆ(0, 1), and hardness parameter Î´ > 0
â€¢ For i = 1, 2, . . .
â€“ Randomly partition V into a green list G of size Î³|V |, and a red list R of size
(1 âˆ’Î³)|V |.
â€“ Sample the token Xi from the following distribution from P where P(Xi = x) =
(
Ï(x)Â·exp(Î´)
P
xâˆˆG Ï(x)Â·exp(Î´)+P
xâˆˆR Ï(x),
if x âˆˆG
Ï(x)
P
xâˆˆG Ï(x)Â·exp(Î´)+P
xâˆˆR Ï(x),
if x âˆˆR
6

â€¢ Let the rejection region R be
{X âˆˆâ„¦: the number of green list tokens in X â‰¥C} .
The above sampling procedures as a whole define the joint distribution of the output
X = X1X2 Â· Â· Â· and the rejection region R, i.e., the Î˜(Î´)-distorted watermarking scheme
PSOFTREDLIST. The detector observes the rejection region via the secret key that the service
provider uses to generate the green and red lists.
Example 2.7 (Complete watermarking algorithm Waksk, Christ et al. (2023)). In Algorithm
3 of Christ et al. (2023), the watermarking scheme (over sample space â„¦= {0, 1}âˆ—) of Ï is
given as follows:
â€¢ Fix threshold C âˆˆR and entropy threshold Î» > 0
â€¢ Select i such that the empirical entropy of X1X2 . . . Xi is greater than or equal to Î»
â€¢ For j = i + 1, i + 2, . . .
â€“ Sample uj âˆˆ[0, 1] uniformly at random.
â€“ Let the binary token Xj be given by Xj =
(
1,
if uj â‰¤Ï(1|X1, . . . , Xjâˆ’1)
0,
otherwise
.
â€¢ Let the rejection region R be given by
(
X :
L
X
j=i+1
log
1
Xjuj + (1 âˆ’Xj)(1 âˆ’uj) â‰¥C
)
.
The above sampling procedures as a whole define the joint distribution of the output
X = X1X2 Â· Â· Â· and the rejection region R, i.e., the 0-distorted watermarking scheme
PWaksk.The detector observes the rejection region via the index i and uj(j > i).
Example 2.8 (Inverse transform sampling WakITS, Kuditipudi et al. (2023)). The inverse
transform sampling scheme in Christ et al. (2023) (over sample space â„¦= [N]âˆ—) of Ï is
given as follows:
â€¢ Fix threshold C âˆˆR, resample size T, and block size k
â€¢ For j = 1, 2, . . . ,
â€“ Let Âµ â†Ï(Â·|X1, . . . , Xjâˆ’1).
â€“ Sample Î¾j = (uj, Ï€j), Î¾(t)
j
= (uâ€²
j, Ï€â€²
j) (t = 1, . . . , T) i.i.d. according to the
following distribution:
* Sample u âˆˆ[0, 1] uniformly at random;
* Sample Ï€ uniformly at random from the space of permutations over the
vocabulary [N].
7

â€“ Let the token Xj be given by
Ï€âˆ’1 (min{Ï€(i) : Âµ({j : Ï€(j) â‰¤Ï€(i)}) â‰¥u}) .
â€¢ Let the rejection region R be
R =
(
X : 1 + PT
t=1 1
 Ï•(X, Î¾(t)) â‰¤Ï•(X, Î¾)

T + 1
â‰¤C
)
where Î¾ = (Î¾1, . . . , Î¾len(X)), Î¾(t) = (Î¾(t)
1 , . . . , Î¾(t)
len(X)), and Ï•(y, Î¾) is given by
min
i=1,...,len(y)âˆ’k+1,
j=1,...,len(Î¾)

d
 {yi+l}kâˆ’1
l=1 , {Î¾(j+l)%len(Î¾)}kâˆ’1
l=1
	
Here d is an alignment cost, set as d(y, (u, Ï€)) = Plen(y)
i=1
ui âˆ’Ï€i(yi)âˆ’1
Nâˆ’1
 in Kuditipudi
et al. (2023). Additionally, a single permutation Ï€ (âˆ€j, t) is used to reduce computation
overhead. The above sampling procedures as a whole define the joint distribution of the
output X = X1X2 Â· Â· Â· and the rejection region R in WakITS.The detector observes the
rejection region via Î¾, Î¾â€².
Using similar approaches as in the above examples, we can encompass the methods of a
number of works (Aaronson, 2022b; Liu et al., 2023; Zhao et al., 2023; Kuditipudi et al.,
2023) into our framework.
3
Statistical Limit in Watermarking
3.1
Rates under the general setting of Problem 2.1
Given the formulation of statistical watermarking, it is demanding to understand its statistical
limit. In this section, we study the following notion of Uniformly Most Powerful (UMP) test,
i.e., the watermarking scheme that achieves the minimum achievable Type II error among
all possible tests with Type I error â‰¤Î±.
Definition 3.1 (Uniformly Most Powerful Watermark). A watermarking scheme P is
called Uniformly Most Powerful (UMP) Ïµ-distorted watermark of level Î±, if it achieves the
minimum achievable Type II error among all Ïµ-distorted watermarking with Type I error
â‰¤Î±.
The following result gives an exact characterization of the UMP watermark and its Type
II error.
Theorem 3.2. For probability measure Ï, the Uniformly Most Powerful Ïµ-distorted water-
mark of level Î±, denoted by Pâˆ—, is given by
Pâˆ—(X = x, R = R0) =
ï£±
ï£´
ï£´
ï£²
ï£´
ï£´
ï£³
Ïâˆ—(x) Â·

1 âˆ§
Î±
Ïâˆ—(x)

,
R0 = {x}
Ïâˆ—(x) Â·

1 âˆ’
Î±
Ïâˆ—(x)

+ ,
R0 = âˆ…
0,
else
8

where Ïâˆ—= arg minTV(Ïâ€²âˆ¥Ï)â‰¤Ïµ
P
xâˆˆâ„¦:Ïâ€²(x)>Î± (Ïâ€²(x) âˆ’Î±) . Its Type II error is given by
min
TV(Ïâ€²âˆ¥Ï)â‰¤Ïµ
X
xâˆˆâ„¦:Ïâ€²(x)>Î±
(Ïâ€²(x) âˆ’Î±) ,
and when |â„¦| â‰¥1
Î± it simplifies to
ï£«
ï£­
X
xâˆˆâ„¦:Ï(x)>Î±
(Ï(x) âˆ’Î±) âˆ’Ïµ
ï£¶
ï£¸
+
.
(1)
The key insight for proving Theorem 3.2 is that maximizing Type II error over level Î±
can be written as a linear program over the coupling distribution P. The detailed proof is
deferred to Appendix A. In the following, we make a few remarks on Theorem 3.2.
Remark 3.3 (Dependence on distortion parameter Ïµ). As seen from the theorem, when a
larger distortion parameter Ïµ is allowed, the Type II error would decrease. This aligns with
the intuition that adding statistical bias would make the output easier to detect (Aaronson,
2022a; Kirchenbauer et al., 2023a). Among all choices of Ïµ, the case Ïµ = 0 is of partic-
ular interest since it preserves the marginal distribution of the service providerâ€™s output.
Therefore, we will focus on this distortion-free case in the following sections.
Remark 3.4 (Intuition behind Pâˆ—). Recall that in practice, the watermarks are implemented
via pseudo-random functions. Therefore, the uniformly most powerful test in Theorem 3.2 is
effectively using a pseudo-random generator to approximate the distribution Ï, combined
with an Î±-clipping to control Type I error. This construction reveals a surprising message:
simply using pseudo-random generator to approximate the distribution is optimal.
Remark 3.5 (Watermarking guarantees). To achieve the upper bound of Theorem 3.2, the
detector needs to access the model and the prompt in order to generate the reject region,
which is not always accessible in many real-world applications. Therefore, the upper
bound of Theorem 3.2 achieves a weaker watermarking guarantee compared with previous
works (Aaronson, 2022a; Kirchenbauer et al., 2023a; Christ et al., 2023). In Section 3.2,
we study model-agnostic watermarking that overcomes this limitation.
Nonetheless, the lower bound in Theorem 3.2 characterizes a fundamental limit of
Problem 2.1, thus providing an information-theoretic lower bound for all watermarks.
Remark 3.6 (Implementation). To implement the UMP watermark using a predetermined
key, one may apply the key to the random seeds used in model generation, and sets the
reject region to be the output with probability 1 âˆ§
Î±
Ïâˆ—(x). To implement the UMP watermark
without the detectorâ€™s knowledge on the secret key, one could hash the first few tokens to
seed the pseudo-random function. In summary, the UMP watermark could use the same key
to watermark many outputs, and the key needs not to be generated at the same time as the
output itself.
Remark 3.7 (Use cases of the UMP watermark). The utilization of the UMP watermark of-
fers an efficient approach for (language model) service providers to determine if instruction-
9

following datasets have been generated by a specific model. In the context of instruction-
following datasets, both the prompt and response are explicitly provided to the detectors,
enabling the UMP watermark to perform accurate watermarking and detection without
extra source of information. This usage is beneficial in identifying and filtering out data
points that have been comtaminated by texts generated from models like GPT-4 (OpenAI,
2023b), thereby preserving the purity and quality of the training data.
Remark 3.8 (Dependence on the randomness of Ï). If Ï is deterministic, the Type II error
P
xâˆˆâ„¦:Ï(x)>Î± (Ï(x) âˆ’Î±) âˆ’Ïµ

+ reduces to 1 âˆ’Î± âˆ’Ïµ and shows limited practical utility of
statistical watermarking. This is expected since when the service provider deterministically
outputs z, it would be impossible to distinguish the watermark distribution with an indepen-
dent output from Î´z. In general, Theorem 3.2 implies that the Type II error decreases when
the randomness in Ï increases, matching the reasoning in previous works Aaronson (2022a);
Christ et al. (2023).
3.2
Rates of model-agnostic watermarking
It is noticeable that for large Q, a Q-watermarking scheme can not perform as good as
a watermarking specifically designed for Ï for any distribution Ï âˆˆQ. This means that
Uniformly Most Powerful Q-Watermarking might not exist in general. To evaluate model-
agnostic watermarking schemes, a natural desideratum is therefore the maximum difference
between its Type II error and the Type II error of the UMP watermarking of Ï over all
distributions Ï, under fixed Type I error. Specifically, we introduce the following notion.
Definition 3.9 (Minimax most powerful model-agnostic watermark). We say that a Q-
agnostic watermark (Î·, {PÏ}ÏâˆˆQ) is of level-Î± if the Type I error of PÏ is less than or equal
to Î± for any Ï âˆˆQ. Define the maximum Type II error loss of (Î·, {PÏ}ÏâˆˆQ) as
Î³(Î·) := sup
ÏâˆˆQ
Î²(PÏ) âˆ’Î²(Pâˆ—
Ï)
where Pâˆ—
Ï is the UMP distortion-free watermark of Ï.
We say that a Q-agnostic watermarking scheme is minimax most powerful, if it mini-
mizes the maximum Type II error loss among all Q-agnostic watermarks of level Î±.
The following result characterizes the Type II error loss of the minimax most powerful
model-agnostic watermarking.
Theorem 3.10. Let |â„¦| = n and suppose Î±n, 1
Î± âˆˆZ2. In the minimax most powerful
model-agnostic watermarking scheme of level-Î±, the marginal distribution of the reject
2For the general case, it suffices to let a1 = 1/(âŒˆ1/Î±âŒ‰) and n1 = âŒˆÎ±1nâŒ‰/Î±1 and augment â„¦with n1 âˆ’n
dummy outcomes. Then Î±1n, 1/Î±1 âˆˆZ and hence the minimax bound for the new sample space with
cardinality n1 and the new Type I error Î±1 yields a nearly-matching bound for (n, Î±).
10

region is given by
Î·âˆ—(A) =
(
1
( n
Î±n),
if |A| = Î±n
0,
otherwise
.
The maximum Type II error loss of the minimax most powerful model-agnostic watermarking
scheme of level-Î± is given by Î³(Î·âˆ—) = (nâˆ’1
Î±
Î±n )
( n
Î±n) . In the regime Î± â†’0+, n â†’+âˆ, we have
Î³(Î·âˆ—) â†’c for some constant c â‰¤eâˆ’1, and when 1/(Î±n) â†’0+ is further satisfied, c = eâˆ’1.
The theorem establishes existence of PÏ for any Ï without explicit construction. To
grasp this concept, consider three sets: U, the output space; V , the set of reject regions;
and W, the subset of U Ã— V defined by {(u, v) : u âˆˆv}. Notice that the type II error is
essentially 1 âˆ’PÏ(W). Therefore, our objective is to establish existence of a probability
measure P over U Ã— V such that its marginal distributions align with Î· and Ï, respectively,
and the probability assigned to W, denoted as P(W), meets a certain lower bound. This
is the question studied by Strassenâ€™s theorem (Strassen, 1965), which stipulates conditions
for the existence of such a measure. Hence, by verifying Strassenâ€™s conditions, we confirm
the existence of the required measure without the necessity of explicitly constructing the
coupling. We defer the detailed proof to Appendix C.
Remark 3.11. Theorem 3.10 implies that for any distribution Ï, the Type II error of model-
agnostic watermark is upper bounded by (nâˆ’1
Î±
Î±n )
( n
Î±n) + P
x:Ï(x)â‰¥Î±(Ï(x) âˆ’Î±). The convergence
Î³(Î·âˆ—) â†’eâˆ’1 implies that the minimax optimal model-agnostic watermark exhibits an
increase in Type II error by an additive factor of eâˆ’1 compared to the UMP watermark in
the worst-case scenario.
Remark 3.12. The eâˆ’1 maximum Type II error loss does not contradict with the hâˆ’2 rates
in previous works (Aaronson, 2022a; Christ et al., 2023; Kuditipudi et al., 2023), because
as n â‰³hâˆ’2, the model distribution (of the sequences of n tokens with average entropy h per
token) is beyond the worst case. Indeed, such distributions have higher differential entropy
than the hard instances in the proof.
Remark 3.12 highlights that the hard instance constructed in Theorem 3.10 may possess
a lower entropy than that of the actual model. Therefore, it raises an important question:
for a smaller class Q that contains distributions with higher entropy, what is the minimum
achievable Type II error loss for Q-agnostic watermarking? It is obvious that the minimax
rate over a higher entropy level should improve upon the previous rate of eâˆ’1.
Towards answering this question, we consider the following class of distributions:
QÎº :=

Ï : sup
Ï‰âˆˆâ„¦
Ï({Ï‰}) â‰¤Îº

where Îº represents the level of randomness and decreases as entropy increases. The
maximum Type II error loss of QÎº-agnostic watermarking (Î·, {PÏ}ÏâˆˆQÎº) is thus given by
Î³(Î·, Îº) :=
max
Ïâˆˆâˆ†(â„¦):supÏ‰âˆˆâ„¦Ï({Ï‰})â‰¤Îº Î²(PÏ) âˆ’Î²(Pâˆ—
Ï)
11

where Pâˆ—
Ï is the UMP distortion-free watermark of Ï. The following result gives an upper
bound of the above quantity, thus answering the question.
Theorem 3.13. Let |â„¦| = n and suppose Î±n, 1
Îº âˆˆZ. Then the maximum Type II error loss
of the minimax QÎº-agnostic watermarking of level-Î± is upper bounded by
Î³(Î·âˆ—, Îº) â‰¤
 nâˆ’Î±n
1/Îº

  n
1/Îº
 .
The proof can be found in Appendix D. When Îº â‰¤Î±, the bound (nâˆ’Î±n
1/Îº )
( n
1/Îº) improves over
eâˆ’1. In the next section, we will apply Theorem 3.13 to the i.i.d. setting where Îº can
be exponentially small. This will lead to an negligible maximum Type II error loss for
model-agnostic watermarking.
3.3
Rates in the i.i.d. setting
In practice, the sample space â„¦is usually a Cartesian product in the form of â„¦âŠ—n
0 . For
example, in large language models, the output takes form of a sequence of tokens, each
coming from the same vocabulary set V . The quantity of practical interest becomes the
minimum number of tokens to achieve certain statistical watermarking guarantee. This
demands specializing and transferring the results from Theorem 3.2 and Theorem 3.13 to
deal with distributions in product measureable spaces, and finding the explicit rates of the
minimum number of required tokens.
In this section, we consider the product distribution Ï = ÏâŠ—n
0
over â„¦âŠ—n
0
and the important
setting of Ïµ = 0 (distortion-free watermarking). We introduce the following two quantities:
â€¢ Let h denote the entropy of Ï0. We use nump(h, Î±, Î²) to denote the minimum number
of tokens required by the UMP watermark to achieve Type I error â‰¤Î± and Type II
error â‰¤Î².
â€¢ Define nminmax(h, Î±, Î²) as the number of tokens required by minimax Qh-agnostic
watermark to achieve Type I error â‰¤Î± and Type II error â‰¤Î², where Qh :=

Ï = ÏâŠ—n
0
: H(Ï0) â‰¥h
	
, i.e. contains all distributions Ï = ÏâŠ—n
0
such that the en-
tropy of Ï0 is â‰¥h.
Together, nump(h, Î±, Î²) and nminmax(h, Î±, Î²) serve as critical thresholds beyond which the
desired statistical conclusions can be drawn regarding the output, making them essential
parameters in watermarking applications.
We start by inspecting the rates in Theorem 3.2 in the i.i.d. setting. The following result
gives a nearly-matching upper bound and lower bound of nump(h, Î±, Î²).
Theorem 3.14. Suppose Î±, Î² < 0.1. We have
nump(h, Î±, Î²) â‰¥O
ï£«
ï£­
ï£«
ï£­
ln 1
h

ln 1
Î± âˆ§ln 1
Î²

h
ï£¶
ï£¸âˆ¨ln 1
Î±
h
ï£¶
ï£¸.
12

Furthermore, let k = |â„¦0|, we have
nump(h, Î±, Î²)
â‰¤â„¦
ï£«
ï£­
ï£«
ï£­
ln k
h Â·

ln 1
Î± âˆ§ln 1
Î²

h
ï£¶
ï£¸âˆ¨ln 1
Î± ln k
h
ï£¶
ï£¸.
Remark 3.15 (Tightness). Up to a constant and logarithmic factor in k, our upper bound
matches the lower bound. Notice that since any model with an arbitrary token set can be
reduced into a model with a binary token set (Christ et al., 2023) (i.e. k = 2), our bound is
therefore tight up to a constant factor.
Using Theorem 3.13 and Theorem 3.14, we are now in the position to characterize
nminmax(h, Î±, Î²). Suppose the sample space is a Cartesian product â„¦= â„¦âŠ—n0
0
and constrain
to product measures over sequences of n0 tokens, like in Section 3.3. We start by the
following relationship:3
1 âˆ’
max
Ï0:H(Ï0)â‰¥h max
Ï‰âˆˆâ„¦0 Ï0({Ï‰}) â‰¥â„¦

h
ln(1/h)

where a detailed derivation can be found in Lemma B.3. It follows that
Îº â‰¤

max
Ï0:H(Ï0)â‰¥h max
Ï‰âˆˆâ„¦0 Ï0({Ï‰})
n0
= eâˆ’â„¦(
n0h
ln(1/h)).
Using this observation and the derivation in Theorem 3.10, Î³(Î·âˆ—, Îº) can be bounded by
(1 âˆ’Î±)1/Îº â‰¤(1 âˆ’Î±)e
â„¦(
n0h
ln(1/h)).
This means that when n0 â‰³
ln(1/h)
h
Â· (ln(1/Î±) + ln(1/Î²)), the maximum Type II error
loss given by Theorem 3.13 and the Type II error of the UMP watermarking given in
Theorem 3.14 can be simultaneously bounded by Î², thus establishing an upper bound.
Furthermore, this rate matches the lower bound in Theorem 3.14, where the guarantee is
weaker (model-nonagnostic). Combining the above arguments, the following result is thus
immediate.
Corollary 3.16. Suppose Î±, Î² < 0.1. We have
nminmax(h, Î±, Î²) = Î˜
ln(1/h)
h
Â· (ln(1/Î±) + ln(1/Î²))

.
Remark 3.17 (Comparison with previous works). As commented in Remark 3.8, the regime
h â‰ª1 is more important and challenging because it is the scenario where watermarking
is difficult. In this regime, our rate of ln(1/h)
h
improves the previous rate of hâˆ’2 in a line of
works (Aaronson, 2022a; Kirchenbauer et al., 2023a; Zhao et al., 2023; Liu et al., 2023;
Kuditipudi et al., 2023), and highlights a fundamental gap between the existing watermarks
and the information-theoretic lower bound.
3In the rest of this section, we omit logarithmic factors in the cardinality of the vocabulary.
13

4
Robust Watermarking
In the context of watermarking large language models, itâ€™s crucial to acknowledge usersâ€™
capability to modify or manipulate model outputs. These modifications include cropping,
paraphrasing, and translating the text, all of which may be employed to subvert watermark
detection. Therefore, in this section, we introduce a graphical framework, modified from
Problem 2.1, to account for potential user perturbations and investigate the optimal water-
marking schemes robust to these perturbations. The formulation here shares similarity with
a concurrent work by Zhang et al. (2023).
Definition 4.1 (Perturbation graph). A perturbation graph over the discrete sample space â„¦
is a directed graph G = (V, E) where V equals â„¦and (u, u) âˆˆE for any u âˆˆV . For any
v âˆˆV , let in(v) = {w âˆˆV : (w, v) âˆˆE} denote the set of vertices with incoming edges to
v, and let out(v) = {w âˆˆV : (v, w) âˆˆE} denote the set of vertices with outcoming edges
from v.
The perturbation graph specifies all the possible perturbations that could be made by the
user: any u âˆˆV can be perturbed into v âˆˆV if and only if (u, v) âˆˆE, i.e., there exists a
directed edge from u to v.
Example 4.2. Consider â„¦= â„¦âŠ—n
0 . Let the user have the capacity to change no more
than c tokens, i.e., perturb any sequence of tokens x = x1x2 Â· Â· Â· xn to another sequence
y = y1y2 Â· Â· Â· yn with Hamming distance less than or equal to c. Then the perturbation graph
is given by G = (V, E) where V = â„¦n and E = {(u, v) : u, v âˆˆV, d(u, v) â‰¤c} (d is the
Hamming distance, i.e., d(x, y) = Pn
i=1 1(xi Ì¸= yi)).
Problem 4.3 (Robust watermarking scheme). A robust watermarking scheme with respect
to a perturbation graph G is a watermarking scheme except that its Type II error is defined as
EX,Râˆ¼P

maxY âˆˆout(X) 1(Y /âˆˆR)

, i.e., the probability of false negative given that the user
adversarially perturbs the output.
The next result characterize the optimum Type II error achievable by robust watermark-
ing, where the proof can be found in Appendix E.
Theorem 4.4. Define the shrinkage operator SG : 2â„¦â†’2â„¦(of a perturbation graph G)
by SG(R) = {x âˆˆâ„¦: out(x) âŠ‚R} and its inverse Sâˆ’1
G (R) = âˆªxâˆˆRout(x). Then the
minimum Type II error of the robust, 0-distorted UMP test of level Î± in Problem 4.3 is given
by the solution of the following Linear Program
min
xâˆˆR|â„¦| 1 âˆ’
X
yâˆˆâ„¦
Ï(y)x(y)
(2)
s.t.
X
yâˆˆin(z)
Ï(y)x(y) â‰¤Î±,
X
zâˆˆâ„¦
x(z) â‰¤1,
0 â‰¤x(z) â‰¤1, âˆ€z âˆˆâ„¦.
14

Scheme / Temperature
0
0.3
0.7
1
Distribution Shift (Kirchenbauer et al., 2023a)
65
63
77
136
Exponential (Aaronson, 2022b)
impossible
890
190
93
Inverse Transform (Kuditipudi et al., 2023)
impossible
+âˆ
434
222
Binary (Christ et al., 2023)
impossible
+âˆ
+âˆ
386
Ours
impossible
60.5
24
15
Table 1: Comparison of our watermark scheme (in the model non-agnostic setting) to
previous works tested on the MARKMYWORDS benchmark by (Piet et al., 2023). For each
watermark scheme and each temperature, we show the (average) minimum number of tokens
needed to detect the watermark under the constraint that type I error is less than Î± = 0.02.
For the first four rows, one can refer to Figure 1 of Piet et al. (2023); +âˆmeans over
half of all generations are not watermarked and â€œimpossibleâ€ means when the temperature
is 0, the text generation procedure is deterministic and the entropy is zero, and thus any
distortion-free watermark scheme does not work.
The UMP watermarking is given by Pâˆ—(X = y, R = R0)
=
ï£±
ï£´
ï£²
ï£´
ï£³
Ï(y) Â· xâˆ—(y),
R0 = Sâˆ’1
G ({y})
Ï(y) Â· (1 âˆ’xâˆ—(y)) ,
R0 = âˆ…
0,
otherwise
where xâˆ—is the solution of Eq. (2).
Remark 4.5 (Dependence on the sparsity of graph). From Eq. (2), we observe that the
perturbation graph influence the optimal Type II error via the constraint set. Indeed, if the
graph is dense, the constraints P
yâˆˆin(z) Ï(y)x(y) â‰¤Î± involve many entries of y âˆˆâ„¦and
thus decrease the value P
yâˆˆâ„¦Ï(y)x(y), thereby increasing the Type II error. On the other
extreme, when the edge set of the perturbation graph is E = {(u, u) : u âˆˆv}, i.e., the user
can not perturb the output to a different value, then optimum of Eq. (2) reduces to Eq. (1)
(setting Ïµ = 0).
5
Experiments
In this section, we show experimental results comparing our watermark scheme to several
previous works. We test our watermark scheme on the MARKMYWORDS benchmark
by Piet et al. (2023). Table 1 shows the average number of tokens needed to detect the
watermark for five different watermark schemes under different temperatures on the MARK-
MYWORDS benchmark. We choose Llama2-7B-chat (Touvron et al., 2023) as the model to
be watermarked and enforce that the type I error is less than Î± = 0.02.
Table 1 shows that our watermark scheme needs significantly fewer tokens to detect the
watermark in the model non-agnostic setting, which provides strong empirical evidence
15

that our watermark scheme is statistically optimal (Theorem 3.14). An exception is that
for the distribution shift scheme (Kirchenbauer et al., 2023b) with low temperature 0.3, the
number of tokens required is only slightly larger than our scheme because the distribution
shift scheme is not distortion-free. Note that the comparison in Table 1 is made under the
model non-agnostic setting (the rate in the model-nonagnostic setting is not fundamentally
different from that in the model-agnostic setting, due to Corollary 3.16) without considering
robustness, while the four previous schemes also work for model agnostic setting with
robustness guarantees. Therefore, our experiments corroborate the improved statistical
trade-offs and highlight the fundamental gap, instead of advocating for the superiority of
any particular watermarking scheme.
6
Conclusions
The understanding of watermarking large language models is advanced by framing it within
the paradigm of hypothesis testing. We find that using a pseudo-random generator to
approximate the model distribution (with probability clipping) yields the optimal Type
II error among all level-Î± tests. Model-agnostic watermarking, reflecting the practical
scenarios where the detector does not have access to the model distribution, enjoys a
minimax bound in Type II errors depending on the model class. In the context where the
output is a sequence of several tokens, we find that the optimal number of i.i.d. tokens
required to detect statistical watermarks is hâˆ’1 log(1/h), improving upon the previous rate
of hâˆ’2 and highlighting a fundamental gap. Finally, the optimal Type II error of robust
UMP watermarking can be characterized via a linear program, which exhibits the trade-off
between robustness and detectability.
Watermarking is an essential technique to diminish the misuse of large language models.
It tackles several critical social issues concerning the malicious usage of language models
such as the contamination of datasets, academic misconduct, creation of fake news, and cir-
culation of misinformation. By laying the theoretical foundation of statistical watermarking,
our paper provides unifying and systematic approach to evaluate the statistical guarantees
of existing and future watermarking schemes, elucidating the statistical limit of (robust)
watermarking problems, and revealing the optimal rates in the important setting of i.i.d.
tokens. In the above ways, our work contributes to the research endeavours on addressing
these societal issues in language modelling, thus having potentially positive social impacts.
Acknowledgements
We would like to thank Julien Piet for his invaluable assistance with the experiments.
Additionally, we are thankful to Or Zamir for his insightful comments on the earlier version
of this manuscript.
16

References
Scott Aaronson. My ai safety lecture for ut effective altruism. Shtetl-Optimized: The
blog of Scott Aaronson. Retrieved on September, 11:2023, 2022a. URL https://
scottaaronson.blog/?p=6823.
Scott Aaronson. Watermarking gpt outputs. Scott Aaronson, 2022b. URL https://www.
scottaaronson.com/talks/watermark.ppt.
Sahar Abdelnabi and Mario Fritz. Adversarial watermarking transformer: Towards tracing
text provenance with data hiding. In 2021 IEEE Symposium on Security and Privacy (SP),
pp. 121â€“140. IEEE, 2021.
Miranda Christ, Sam Gunn, and Or Zamir. Undetectable watermarks for language models.
arXiv preprint arXiv:2306.09194, 2023.
Jaiden Fairoze, Sanjam Garg, Somesh Jha, Saeed Mahloujifar, Mohammad Mahmoody, and
Mingyuan Wang. Publicly detectable watermarking for language models. arXiv preprint
arXiv:2310.18491, 2023.
Pierre Fernandez, Antoine Chaffin, Karim Tit, Vivien Chappelier, and Teddy Furon.
Three bricks to consolidate watermarks for large language models.
arXiv preprint
arXiv:2308.00113, 2023.
Yu Fu, Deyi Xiong, and Yue Dong. Watermarking conditional text generation for ai
detection: Unveiling challenges and a semantic-aware watermark remedy. arXiv preprint
arXiv:2307.13808, 2023.
Nurul Shamimi Kamaruddin, Amirrudin Kamsin, Lip Yee Por, and Hameedur Rahman.
A review of text watermarking: theory, methods, and applications. IEEE Access, 6:
8011â€“8028, 2018.
John Kirchenbauer, Jonas Geiping, Yuxin Wen, Jonathan Katz, Ian Miers, and Tom Goldstein.
A watermark for large language models. arXiv preprint arXiv:2301.10226, 2023a.
John Kirchenbauer, Jonas Geiping, Yuxin Wen, Manli Shu, Khalid Saifullah, Kezhi Kong,
Kasun Fernando, Aniruddha Saha, Micah Goldblum, and Tom Goldstein. On the reliability
of watermarks for large language models. arXiv preprint arXiv:2306.04634, 2023b.
Ryuto Koike, Masahiro Kaneko, and Naoaki Okazaki.
Outfox: Llm-generated essay
detection through in-context learning with adversarially generated examples. arXiv
preprint arXiv:2307.11729, 2023.
Rohith Kuditipudi, John Thickstun, Tatsunori Hashimoto, and Percy Liang.
Robust
distortion-free watermarks for language models. arXiv preprint arXiv:2307.15593, 2023.
17

Aiwei Liu, Leyi Pan, Xuming Hu, Shuâ€™ang Li, Lijie Wen, Irwin King, and Philip S Yu. A
private watermark for large language models. arXiv preprint arXiv:2307.16230, 2023.
OpenAI. Gpt-4 technical report, 2023a.
R OpenAI. Gpt-4 technical report. arXiv, pp. 2303â€“08774, 2023b.
Julien Piet, Chawin Sitawarin, Vivian Fang, Norman Mu, and David Wagner.
Mark
my words: Analyzing and evaluating language model watermarks.
arXiv preprint
arXiv:2312.00273, 2023.
Stefano Giovanni Rizzo, Flavio Bertini, and Danilo Montesi. Fine-grain watermarking for
intellectual property protection. EURASIP Journal on Information Security, 2019:1â€“20,
2019.
Ryoma Sato, Yuki Takezawa, Han Bao, Kenta Niwa, and Makoto Yamada. Embarrassingly
simple text watermarks. arXiv preprint arXiv:2310.08920, 2023.
Volker Strassen. The existence of probability measures with given marginals. The Annals of
Mathematical Statistics, 36(2):423â€“439, 1965.
Ruixiang Tang, Yu-Neng Chuang, and Xia Hu. The science of detecting llm-generated texts.
arXiv preprint arXiv:2303.07205, 2023.
Flemming TopsÃ¸e. Bounds for entropy and divergence for distributions over a two-element
set. J. Ineq. Pure Appl. Math, 2(2), 2001.
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei,
Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. Llama 2:
Open foundation and fine-tuned chat models. arXiv preprint arXiv:2307.09288, 2023.
Ashish Venugopal, Jakob Uszkoreit, David Talbot, Franz Och, and Juri Ganitkevitch. Water-
marking the outputs of structured prediction with an application in statistical machine
translation. In Proceedings of the 2011 Conference on Empirical Methods in Natural
Language Processing, pp. 1363â€“1372, Edinburgh, Scotland, UK., July 2011. Association
for Computational Linguistics. URL https://aclanthology.org/D11-1126.
James Vincent. AI-generated answers temporarily banned on coding q&a site stack overflow.
The Verge, 5, 2022.
Lean Wang, Wenkai Yang, Deli Chen, Hao Zhou, Yankai Lin, Fandong Meng, Jie Zhou, and
Xu Sun. Towards codable text watermarking for large language models. arXiv preprint
arXiv:2307.15992, 2023.
Borui Yang, Wei Li, Liyao Xiang, and Bo Li. Towards code watermarking with dual-channel
transformations. arXiv preprint arXiv:2309.00860, 2023.
18

Xi Yang, Jie Zhang, Kejiang Chen, Weiming Zhang, Zehua Ma, Feng Wang, and Nenghai
Yu. Tracing text provenance via context-aware lexical substitution. In Proceedings of the
AAAI Conference on Artificial Intelligence, volume 36, pp. 11613â€“11621, 2022.
KiYoon Yoo, Wonhyuk Ahn, and Nojun Kwak. Advancing beyond identification: Multi-bit
watermark for language models. arXiv preprint arXiv:2308.00221, 2023.
Hanlin Zhang, Benjamin L Edelman, Danilo Francati, Daniele Venturi, Giuseppe Ateniese,
and Boaz Barak. Watermarks in the sand: Impossibility of strong watermarking for
generative models. arXiv preprint arXiv:2311.04378, 2023.
Xuandong Zhao, Prabhanjan Ananth, Lei Li, and Yu-Xiang Wang. Provable robust water-
marking for ai-generated text. arXiv preprint arXiv:2306.17439, 2023.
19

A
Proof of Theorem 3.2
Proof. Let Ïâ€² denote the marginal probability of X and let Î· denote the marginal probability
of R. In the bound of Type I error, choosing Ï€ = Î´y yields
Î± â‰¥PXâˆ¼Ï€,Râˆ¼P(â„¦,Â·)(X âˆˆR)
= PRâˆ¼Î·(y âˆˆR)
=
X
Râˆˆ2â„¦
 X
xâˆˆâ„¦
Ïâ€²(x)P(R|x)
!
Â· 1(y âˆˆR).
(3)
Now notice that
P(X âˆˆR) = EP[1(X âˆˆR)]
=
X
yâˆˆâ„¦
X
Râˆˆ2â„¦
Ïâ€²(y)P(R|y)1(y âˆˆR)
=
X
yâˆˆâ„¦
 X
Râˆˆ2â„¦
Ïâ€²(y)P(R|y) Â· 1(y âˆˆR)
!
|
{z
}
A(y)
.
For the term A(y), we first know that A(y) â‰¤Ïâ€²(y). Applying Eq. (3), we further have
A(y) â‰¤
X
Râˆˆ2â„¦
 X
xâˆˆâ„¦
Ïâ€²(x)P(R|x)
!
Â· 1(y âˆˆR)
â‰¤Î±.
Combining the above two inequalies, it follows that
P(X âˆˆR) â‰¤
X
yâˆˆâ„¦
(Î± âˆ§Ïâ€²(y))
= 1 âˆ’
X
xâˆˆâ„¦:Ïâ€²(x)>Î±
(Ïâ€²(x) âˆ’Î±)
â‰¤1 âˆ’
min
TV(Ïâ€²âˆ¥Ï)â‰¤Ïµ
X
xâˆˆâ„¦:Ïâ€²(x)>Î±
(Ïâ€²(x) âˆ’Î±)
â‰¤1 âˆ’
ï£«
ï£­
X
xâˆˆâ„¦:Ï(x)>Î±
(Ï(x) âˆ’Î±) âˆ’Ïµ
ï£¶
ï£¸
+
where first equality is achieved by
Ïâ€² = arg
min
TV(Ïâ€²âˆ¥Ï)â‰¤Ïµ
X
xâˆˆâ„¦:Ïâ€²(x)>Î±
(Ïâ€²(x) âˆ’Î±)
and the second inequality is achieved when P
xâˆˆâ„¦:Ï(x)<Î± (Î± âˆ’Ï(x)) â‰¥Ïµ, a sufficient condi-
tion for which being |â„¦| â‰¥1/Î±. This establishes the optimal Type II error.
Finally, to verify that Pâˆ—satisfies the conditions, the condition TV(Pâˆ—(Â·, 2â„¦)âˆ¥Ï) â‰¤Ïµ is
20

apparently satisfied. For any y âˆˆâ„¦we have
PRâˆ¼Î·(y âˆˆR) =
X
xâˆˆâ„¦
Ïâˆ—(x) Â· P(R = {x}) Â· 1(y = x)
= Ïâˆ—(y) Â·

1 âˆ§
Î±
Ïâˆ—(y)

â‰¤Î±.
This implies the supÏ€âˆˆâˆ†(â„¦) PY âˆ¼Ï€,(X,R)âˆ¼Pâˆ—(Y âˆˆR) â‰¤Î± because any Ï€ can be written as
linear combination of Î´y. Moreover,
Pâˆ—(X âˆˆR) =
X
xâˆˆâ„¦
Ïâˆ—(x) Â· P(R = {x})
=
X
yâˆˆâ„¦
(Î± âˆ§Ïâˆ—(y))
= 1 âˆ’
X
xâˆˆâ„¦:Ïâˆ—(x)>Î±
(Ïâˆ—(x) âˆ’Î±) .
This verifies that Ïâˆ—achieves the advertised Type II error.
B
Proof of Theorem 3.14
Proof. Throughout the proof we assume that h < 1/4, otherwise the bounds become trivial.
We first prove the lower bound. For this purpose, we construct the hard instance: let
q0 = Hâˆ’1
b (h) (take the one â‰¥1/2) where Hb is the binary entropy function defined by
Hb(x) = âˆ’x ln x âˆ’(1 âˆ’x) ln(1 âˆ’x), and set Ï0 = (1 âˆ’q0)Î´x1 + q0Î´x2 where x1, x2 are
two different elements in â„¦0. Then Lemma B.2 implies that q0 â‰¥3/4. By Theorem 3.2,
Î² = 1 âˆ’P(X âˆˆR) =
X
xâˆˆâ„¦:Ï(x)>Î±
(Ï(x) âˆ’Î±)
â‰¥1
2 Â· P (Ï(X) â‰¥2Î±)
= 1
2 Â· P
 n
X
i=1
ln Ï0(Xi) â‰¥ln(2Î±)
!
â‰¥1(n ln q0 â‰¥ln(2Î±)) Â· 1
2qn
0
â‰¥1(2n(1 âˆ’q0) â‰¤âˆ’ln(2Î±)) Â· 1
2 exp (âˆ’2n(1 âˆ’q0))
â‰¥1
 
n â‰¤
ln 1
2Î±
2h/ ln ln 2
h
!
Â· 1
2 exp
 
âˆ’2nh
ln ln 2
h
!
21

where the last inequality follows from Lemma B.3. It follows that
n(h, Î±, Î²) â‰¥ln ln 2
h
2h
Â·

ln 1
2Î± âˆ§ln 1
2Î²

.
(4)
Furthermore, suppose n â‰¤
ln
1
2Î±
4(1âˆ’q0) ln
1
1âˆ’q0
. Define Y = Pn
i=1 1(Ï0(Xi) = 1 âˆ’q0), then
notice that Y âˆ¼Binom(n, 1 âˆ’q0) and if Y â‰¤
ln
1
2Î±
2 ln
1
1âˆ’q0
, then
n
X
i=1
ln Ï0(Xi) â‰¥
ln 1
2Î±
2 ln
1
1âˆ’q0
Â· ln(1 âˆ’q0) + n Â· ln q0
â‰¥ln(2Î±)
where the last inequality is due to n Â· ln q0 â‰¥âˆ’2(1 âˆ’q0)n â‰¥âˆ’2(1 âˆ’q0)
ln
1
2Î±
4(1âˆ’q0) ln
1
1âˆ’q0
=
ln(2Î±)
2 ln
1
1âˆ’q0
â‰¥ln(2Î±)
2
. Applying this and Markovâ€™s inequality,
P
 n
X
i=1
ln Ï0(Xi) â‰¥ln(2Î±)
!
â‰¥P
 
Y â‰¤2 ln 1
2Î±
ln
1
1âˆ’q0
!
â‰¥1 âˆ’n(1 âˆ’q0)
2 ln
1
2Î±
ln
1
1âˆ’q0
â‰¥1
2,
A contradiction to P(Ï(X) â‰¥2Î±) â‰¤2Î². As a result,
n(h, Î±, Î²) â‰¥
ln 1
2Î±
4(1 âˆ’q0) ln
1
1âˆ’q0
â‰¥ln 1
2Î±
4h .
(5)
Combining Eq. (4) and Eq. (5), we established the lower bound.
For the upper bound, we define q = maxxâˆˆâ„¦0 Ï0(x), then Lemma B.2 implies that
q â‰¥1/2. Define Y = Pn
i=1 1(Ï0(Xi) Ì¸= q) (recall that Y âˆ¼Binom(n, 1 âˆ’q)). It suffices
to show when
n = 900
 
2 ln 9k
h
h
Â·

ln 1
Î± âˆ§ln 1
Î²
!
âˆ¨(18 + 36 ln(9k)) ln 1
Î±
h
the Type II error of the UMP watermark 1 âˆ’Pâˆ—(X âˆˆR) â‰¤Î².
22

By Theorem 3.2 and Bennettâ€™s inequality,
1 âˆ’Pâˆ—(X âˆˆR) =
X
xâˆˆâ„¦:Ï(x)>Î±
(Ï(x) âˆ’Î±)
â‰¤P (Ï(X) â‰¥Î±)
= P
 n
X
i=1
ln Ï0(Xi) â‰¥ln(Î±)
!
â‰¤P
 
Y â‰¤ln 1
Î±
ln
1
1âˆ’q
!
â‰¤exp
ï£«
ï£¬
ï£­âˆ’nq(1 âˆ’q)Î¸
ï£«
ï£¬
ï£­
1 âˆ’q âˆ’
ln 1
Î±
n ln
1
1âˆ’q
q(1 âˆ’q)
ï£¶
ï£·
ï£¸
ï£¶
ï£·
ï£¸
(6)
where Î¸(x) = (1+x) ln(1+x)âˆ’x; the penultimate inequality follows from Pn
i=1 ln Ï0(Xi) â‰¤
Y ln(1 âˆ’q).
Notice that by Lemma B.2,
(1 âˆ’q) ln
1
1 âˆ’q â‰¥
h
9 ln 9k ln(9k)
h
Â· ln ln 1
h
h
= h Â·
ln ln 1
h + ln 1
h
9
 ln 1
h + ln(9k ln(9k))

â‰¥
h
9 + ln(9k ln(9k)).
Since n â‰¥
(18+36 ln(9k ln(9k))) ln 1
Î±
h
, we have n â‰¥
2
1âˆ’q
ln 1
Î±
ln
1
1âˆ’q . Under this condition, we have the
simplification
Î¸
ï£«
ï£¬
ï£­
1 âˆ’q âˆ’
ln 1
Î±
n ln
1
1âˆ’q
q(1 âˆ’q)
ï£¶
ï£·
ï£¸â‰¥Î¸
 1
2q

â‰¥1
50.
23

Plugging back to Eq. (6), we have
1 âˆ’Pâˆ—(X âˆˆR) â‰¤exp
ï£«
ï£¬
ï£­âˆ’nq(1 âˆ’q)Î¸
ï£«
ï£¬
ï£­
1 âˆ’q âˆ’
ln 1
Î±
n ln
1
1âˆ’q
q(1 âˆ’q)
ï£¶
ï£·
ï£¸
ï£¶
ï£·
ï£¸
â‰¤exp

âˆ’n(1 âˆ’q)
100

â‰¤exp
 
âˆ’
nh
900 ln 9k ln(9k)
h
!
(7)
where we applied Lemma B.3 in the last step.
Furthermore, we have
1 âˆ’P(X âˆˆR) â‰¤P
 n
X
i=1
ln Ï0(Xi) â‰¥ln(Î±)
!
â‰¤1

n â‰¤ln Î±
ln q

â‰¤1
 
n â‰¤900
 
ln 9k ln(9k)
h
h
Â· ln 1
Î±
!!
(8)
where the last step is due to Lemma B.3. Combining Eq. (7) and Eq. (8), we know that
1âˆ’Pâˆ—(X âˆˆR) â‰¤Î² when n â‰¥900

ln 9k ln(9k)
h
h
Â·

ln 1
Î± âˆ§ln 1
Î²

. This establishes the upper
bound.
B.1
Supporting lemmata
Lemma B.1 (TopsÃ¸e (2001), Theorem 1.2). Define the binary entropy function Hb : (0, 1) â†’
R as Hb(x) = âˆ’x ln x âˆ’(1 âˆ’x) ln(1 âˆ’x). Then 4x(1 âˆ’x) â‰¤Hb(x) â‰¤(4x(1 âˆ’x))1/ ln 4.
Lemma B.2. Suppose Ï is a probability measure over â„¦such that H(Ï) = h, define
q = maxxâˆˆâ„¦Ï(x). If H(Ï) â‰¤1/4, then q â‰¥1/2. Furthermore, if Hb(q) â‰¤1/4, then
q â‰¥3/4.
Proof. Suppose q â‰¤1/2. By convexity of H,
H(Ï) â‰¥âˆ’
1
q

q ln q â‰¥âˆ’1
2 ln 1
2 â‰¥1/4.
This is a contradiction.
Suppose q â‰¤3/4, then Lemma B.1 implies that
Hb(q) â‰¥4q(1 âˆ’q) â‰¥1/4.
This is a contradiction.
24

Lemma B.3. Suppose Ï is a probability measure over â„¦such that H(Ï) = h and |â„¦| = k.
Define q = maxxâˆˆâ„¦Ï(x). If q â‰¥1/2, then we have
h
9 ln 9k ln(9k)
h
â‰¤1 âˆ’q â‰¤
h
ln ln 2
h
Proof. We have
H(Ï) â‰¥âˆ’(1 âˆ’q) ln(1 âˆ’q) â‰¥(1 âˆ’q) Â· ln 2.
It follows that
h â‰¥âˆ’(1 âˆ’q) ln(1 âˆ’q)
â‰¥(1 âˆ’q) ln ln 2
h .
Therefore 1 âˆ’q â‰¤
h
ln ln 2
h .
By the convexity of H and âˆ’q ln q â‰¤2(1 âˆ’q),
H(Ï) â‰¤âˆ’q ln q âˆ’(1 âˆ’q) ln 1 âˆ’q
k
â‰¤(1 âˆ’q) ln
9k
1 âˆ’q.
This means that
h2 â‰¤(1 âˆ’q)2

ln
9k
1 âˆ’q
2
â‰¤2(1 âˆ’q)2  ln2(9k) + ln2(1 âˆ’q)

â‰¤2(1 âˆ’q)2 ln2(9k) + (1 âˆ’q) Â·
 2(1 âˆ’q) ln2(1 âˆ’q)

â‰¤(1 âˆ’q) Â· (ln2(9k) + 18)
(9)
where the last inequality is due to 2(1 âˆ’q) â‰¤1 and 2(1 âˆ’q) ln2(1 âˆ’q) â‰¤18. It follows that
h â‰¤(1 âˆ’q) ln
9k
1 âˆ’q
â‰¤9(1 âˆ’q) ln 9k ln(9k)
h
where the last step is because ln
1
1âˆ’q â‰¤2 ln ln2(9k)+18
h
â‰¤9 ln ln(9k)
h
, using Eq. (9). This
establishes 1 âˆ’q â‰¥
h
9 ln 9k ln(9k)
h
.
C
Proof of Theorem 3.10
Proof. Lower bound. Let m = 1
Î±. Notice that for any level-Î± model-agnostic watermarking
(Î·, {PÏ}Ïâˆˆâˆ†(â„¦,F)), the following holds
X
Aâˆˆ2â„¦
Î·(A)1(x âˆˆA) â‰¤Î±, âˆ€x âˆˆâ„¦.
25

Furthermore, for any Ï0 = Unif(i1, i2, . . . , im), we have Î²(Pâˆ—
Ï0) = 0 and
Î²(PÏ0) â‰¥PAâˆ¼Î· ({i1, . . . , im} âˆ©A = âˆ…)
â‰¥
X
A
Î·(A) Â·
m
Y
j=1
1(ij /âˆˆA).
By probabilistic method,
Î²(PÏ0) â‰¥
max
i1<Â·Â·Â·<im
X
A
Î·(A) Â·
m
Y
j=1
1(ij /âˆˆA)
â‰¥
1
 n
m

X
i1<Â·Â·Â·<im
X
A
Î·(A) Â·
m
Y
j=1
1(ij /âˆˆA).
It follows that the maximum Type II error loss is lower bounded by the following linear
program
vâˆ—= min
Î·
1
 n
m

X
i1<Â·Â·Â·<im
X
A
Î·(A) Â·
m
Y
j=1
1(ij /âˆˆA)
s.t.
X
Aâˆˆ2â„¦
Î·(A)1(x âˆˆA) â‰¤Î±, âˆ€x âˆˆâ„¦,
X
Aâˆˆ2â„¦
Î·(A) = 1, Î·(A) â‰¥0, âˆ€A âˆˆ2â„¦.
By duality, this is bounded by
min
Î·â‰¥0 max
Î¾,Î¶â‰¥0
1
 n
m

 
X
i1<Â·Â·Â·<im
X
A
Î·(A) Â·
m
Y
j=1
1(ij /âˆˆA) +
X
x
Î¾(x)
 X
Aâˆˆ2â„¦
Î·(A)1(x âˆˆA) âˆ’Î±
!
+ Î¶ Â·
 X
Aâˆˆ2â„¦
Î·(A) âˆ’1
! !
= max
Î¾,Î¶â‰¥0 min
Î·â‰¥0
1
 n
m

 X
A
Î·(A) Â·
 
X
i1<Â·Â·Â·<im
m
Y
j=1
1(ij /âˆˆA) +
X
x
Î¾(x)1(x âˆˆA) + Î¶
!
âˆ’Î± Â·
X
x
Î¾(x) âˆ’Î¶
!
â‰¥min
Î·â‰¥0
1
 n
m

n
X
l=1
X
|A|=l
Î·(A) Â·
n âˆ’l
m

+ l Â· Î¾âˆ—+ Î¶âˆ—

âˆ’Î±nÎ¾âˆ—+ Î¶âˆ—
 n
m

where Î¾âˆ—=
 nâˆ’Î±nâˆ’1
mâˆ’1

and Î¶âˆ—= 0.
Since f(l) :=
 nâˆ’l
m

+ l Â· Î¾âˆ—+ Î¶âˆ—is a convex function and achieves the minimum at
lâˆ—= Î±n, we have
 nâˆ’l
m

+ l Â· Î¾âˆ—+ Î¶âˆ—â‰¥
 nâˆ’Î±n
m

+ Î±n Â·
 nâˆ’Î±nâˆ’1
mâˆ’1

for all l âˆˆ[n] and thus
RHS â‰¥
 nâˆ’Î±n
m

 n
m

=
 nâˆ’m
Î±n

  n
Î±n
 =
 nâˆ’1
Î±
Î±n

  n
Î±n
 .
26

Upper bound. Notice that the marginal distribution of reject region
Î·âˆ—(A) =
(
1
( n
Î±n),
if |A| = Î±n
0,
otherwise
.
already guarantees Type I error â‰¤Î±. It suffices to show (*): for any Ï âˆˆâˆ†(â„¦, F), there
exists a coupling PÏ of Î·âˆ—and Ï such that P(x,A)âˆ¼PÏ(x /âˆˆA) â‰¤(nâˆ’1
Î±
Î±n )
( n
Î±n) +P
x:Ï(x)â‰¥Î±(Ï(x)âˆ’Î±).
Define p as the projection from â„¦Ã— 2â„¦to 2â„¦, i.e.
p(V ) = {A âˆˆ2â„¦: âˆƒx âˆˆ
â„¦, s.t.(x, A) âˆˆV }. Let W := {(x, A) âˆˆâ„¦Ã— 2â„¦: x âˆˆA}. To show the above, we
check the Strassenâ€™s condition
Ï(U) âˆ’Î·âˆ— p
 W âˆ©(U Ã— 2â„¦)

â‰¤
 nâˆ’1
Î±
Î±n

  n
Î±n
 +
X
x:Ï(x)â‰¥Î±
(Ï(x) âˆ’Î±), âˆ€U âŠ‚â„¦.
(10)
Indeed, given Eq. (10), Theorem 11 in Strassen (1965) establishes (*).
In the rest of the proof, we show Eq. (10). Fix U with cardinality k. First notice that
Ï(U) âˆ’P
x:Ï(x)â‰¥Î±(Ï(x) âˆ’Î±) â‰¤(Î±k âˆ§1). Since p
 W âˆ©(U Ã— 2â„¦)

= {A âˆˆ2â„¦: âˆƒi âˆˆ
U, s.t. i âˆˆA}, we have
Î·âˆ— p
 W âˆ©(U Ã— 2â„¦)

â‰¥1 âˆ’
 nâˆ’k
Î±n

  n
Î±n
 = 1 âˆ’
 nâˆ’Î±n
k

 n
k

.
If k â‰¤1
Î±, then because g(k) := Î±k âˆ’1 + (nâˆ’Î±n
k )
(n
k)
is convex and takes maximum (
nâˆ’Î±n
1
Î± )
(
n
1
Î±)
=
(nâˆ’1
Î±
Î±n )
( n
Î±n) at kâˆ—= 1
Î±, we have
Ï(U) âˆ’Î·âˆ— p
 W âˆ©(U Ã— 2â„¦)

â‰¤Î±k âˆ’1 +
 nâˆ’Î±n
k

 n
k

+
X
x:Ï(x)â‰¥Î±
(Ï(x) âˆ’Î±)
=
 nâˆ’1
Î±
Î±n

  n
Î±n
 +
X
x:Ï(x)â‰¥Î±
(Ï(x) âˆ’Î±).
If k â‰¥1
Î±, then since (nâˆ’Î±n
k )
(n
k)
= (nâˆ’k
Î±n )
( n
Î±n) is monotonously decreasing in k,
Ï(U) âˆ’Î·âˆ— p
 W âˆ©(U Ã— 2â„¦)

â‰¤
 nâˆ’Î±n
k

 n
k

+
X
x:Ï(x)â‰¥Î±
(Ï(x) âˆ’Î±)
=
 nâˆ’1
Î±
Î±n

  n
Î±n
 +
X
x:Ï(x)â‰¥Î±
(Ï(x) âˆ’Î±).
Combining, we establishes Eq. (10).
Under the condition Î± â†’0+ and 1/(Î±n) â†’0+, the rate displayed in Theorem 1
27

simplifies to:
(n âˆ’Î±n)(n âˆ’Î±n âˆ’1) Â· Â· Â· (n âˆ’Î±n âˆ’1/Î± + 1)
n(n âˆ’1) Â· Â· Â· (n âˆ’1/Î± + 1)
â‰(1 âˆ’Î±)1/Î± â†’eâˆ’1.
This concludes the proof.
D
Proof of Theorem 3.13
Proof. The proof largely follows the proof of Theorem 3.10. Notice that the marginal
distribution of reject region
Î·âˆ—(A) =
(
1
( n
Î±n),
if |A| = Î±n
0,
otherwise
.
already guarantees Type I error â‰¤Î±. In what remains, we define p and W in the same way
in the proof of Theorem 3.10 and check the Strassenâ€™s condition
Ï(U) âˆ’Î·âˆ— p
 W âˆ©(U Ã— 2â„¦)

â‰¤
 nâˆ’1
Î±
Î±n

  n
Î±n
 +
X
x:Ï(x)â‰¥Î±
(Ï(x) âˆ’Î±), âˆ€U âŠ‚â„¦.
(11)
Fix U with cardinality k. Due to the condition of supÏ‰âˆˆâ„¦Ï({Ï‰}) â‰¤Îº, we have Ï(U) âˆ’
P
x:Ï(x)â‰¥Î±(Ï(x) âˆ’Î±) â‰¤(Îºk âˆ§1). Since p
 W âˆ©(U Ã— 2â„¦)

= {A âˆˆ2â„¦: âˆƒi âˆˆU, s.t. i âˆˆ
A}, we have
Î·âˆ— p
 W âˆ©(U Ã— 2â„¦)

â‰¥1 âˆ’
 nâˆ’k
Î±n

  n
Î±n
 = 1 âˆ’
 nâˆ’Î±n
k

 n
k

.
If k â‰¤1
Îº, then
Ï(U) âˆ’Î·âˆ— p
 W âˆ©(U Ã— 2â„¦)

â‰¤Îºk âˆ’1 +
 nâˆ’Î±n
k

 n
k

+
X
x:Ï(x)â‰¥Î±
(Ï(x) âˆ’Î±)
=
 nâˆ’1
Îº
Î±n

  n
Î±n
 +
X
x:Ï(x)â‰¥Î±
(Ï(x) âˆ’Î±).
where the second step follows from the fact that g(k) := Îºk âˆ’1 + (nâˆ’Î±n
k )
(n
k)
is convex and
takes maximum (
nâˆ’Î±n
1
Îº )
(
n
1
Îº)
= (nâˆ’1
Îº
Î±n )
( n
Î±n) at kâˆ—= 1
Îº.
If k â‰¥1
Îº, then
Ï(U) âˆ’Î·âˆ— p
 W âˆ©(U Ã— 2â„¦)

â‰¤
 nâˆ’Î±n
k

 n
k

+
X
x:Ï(x)â‰¥Î±
(Ï(x) âˆ’Î±)
=
 nâˆ’1
Îº
Î±n

  n
Î±n
 +
X
x:Ï(x)â‰¥Î±
(Ï(x) âˆ’Î±).
28

since (nâˆ’Î±n
k )
(n
k)
= (nâˆ’k
Î±n )
( n
Î±n) is monotonously decreasing in k Combining, we establishes Eq. (11).
Combining the above cases, we checked Strassenâ€™s condition and hence the statement
follows.
E
Proof of Theorem 4.4
Proof. Throughout the proof we omit the subscript in the shrinkage operator S, as G is
fixed. First notice that
EX,Râˆ¼P

min
Y âˆˆout(X) 1(Y âˆˆR)

= P(X âˆˆS(R))
=
X
yâˆˆâ„¦
X
Râˆˆ2â„¦
Ï(y)P(R|y)1(y âˆˆS(R)).
Further, notice that y âˆˆin(z) and y âˆˆS(R) implies that z âˆˆR, thus
X
yâˆˆin(z)
X
Râˆˆ2â„¦
Ï(y)P(R|y)1(y âˆˆS(R)) â‰¤
X
yâˆˆin(z)
X
Râˆˆ2â„¦
Ï(y)P(R|y)1(z âˆˆR)
â‰¤
X
yâˆˆâ„¦
X
Râˆˆ2â„¦
Ï(y)P(R|y)1(z âˆˆR)
= PXâˆ¼Î´z,Râˆ¼P(â„¦,Â·)(X âˆˆR)
â‰¤Î±.
It follows that the optimum Type II error is lower bounded by the optimum of the following
Linear Program
min
P
1 âˆ’
X
yâˆˆâ„¦
X
Râˆˆ2â„¦
Ï(y)P(R|y)1(y âˆˆS(R))
(12)
s.t.
X
yâˆˆin(z)
X
Râˆˆ2â„¦
Ï(y)P(R|y)1(y âˆˆS(R)) â‰¤Î±,
X
Râˆˆ2â„¦
P(R|z) = 1, 0 â‰¤P(R|z) â‰¤1, âˆ€z âˆˆâ„¦, R âˆˆ2â„¦.
We claim that the minimum in Eq. (12) is equal to the minimum of Eq. (2). Indeed, it
suffices to show that Eq. (12) is optimized when P(Â·|y0) is supported on {âˆ…, Sâˆ’1({y0})}
(then setting x(y) â‰¡P(Sâˆ’1({y})|y) reduces Eq. (12) to Eq. (2)). To see this, consider any
minimizer eP such that there exists y0 âˆˆâ„¦and R0 /âˆˆ{âˆ…, Sâˆ’1({y0})}, with eP(R0|y0) > 0.
We will show that there exists Â¯P such that it achieves the no greater objective value, and
satisfies |supp( Â¯P(Â·|y0)) âˆ©{âˆ…, Sâˆ’1({y0})}c | = |supp( eP(Â·|y0)) âˆ©{âˆ…, Sâˆ’1({y0})}c | âˆ’1 and
|supp( Â¯P(Â·|y))| = |supp( eP(Â·|y))| for all other y âˆˆâ„¦. Iteratively applying this argument, we
reduce supp( eP(Â·|y)) âˆ©{âˆ…, Sâˆ’1({y})}c to âˆ…for any y âˆˆâ„¦and thereby prove the claim.
Consider the following two cases.
29

Case 1: y0 /âˆˆS(R0). Then letting
Â¯P(R|y) =
ï£±
ï£´
ï£²
ï£´
ï£³
eP(R0|y) + eP(R|y),
y = y0, R = âˆ…
0,
y = y0, R = R0
eP(R|y),
o.w.,
we observe that
X
yâˆˆâ„¦
X
Râˆˆ2â„¦
Ï(y) eP(R|y)1(y âˆˆS(R)) =
X
yâˆˆâ„¦
X
Râˆˆ2â„¦
Ï(y) Â¯P(R|y)1(y âˆˆS(R))
and Â¯P satisfies all the constraints in Eq. (12). It is obvious from the construction of Â¯P
that |supp( Â¯P(Â·|y0)) âˆ©{âˆ…, Sâˆ’1({y0})}c | = |supp( eP(Â·|y0)) âˆ©{âˆ…, Sâˆ’1({y0})}c | âˆ’1 and
|supp( Â¯P(Â·|y))| = |supp( eP(Â·|y))| for all other y âˆˆâ„¦.
Case 2: y0 âˆˆS(R0). Then letting
Â¯P(R|y) =
ï£±
ï£´
ï£²
ï£´
ï£³
eP(R0|y) + eP(R|y),
y = y0, R = Sâˆ’1({y0})
0,
y = y0, R = R0
eP(R|y),
o.w.
,
we observe that
X
yâˆˆâ„¦
X
Râˆˆ2â„¦
Ï(y) eP(R|y)1(y âˆˆS(R)) =
X
yâˆˆâ„¦
X
Râˆˆ2â„¦
Ï(y) Â¯P(R|y)1(y âˆˆS(R))
and Â¯P satisfies all the constraints in Eq. (12) due to 1(y âˆˆS(R0)) â‰¥1(y âˆˆS({y0})) for
any y âˆˆâ„¦. From the construction of Â¯P, we know that |supp( Â¯P(Â·|y0))âˆ©{âˆ…, Sâˆ’1({y0})}c | =
|supp( eP(Â·|y0)) âˆ©{âˆ…, Sâˆ’1({y0})}c | âˆ’1 and |supp( Â¯P(Â·|y))| = |supp( eP(Â·|y))| for all other
y âˆˆâ„¦.
Combining the above cases, we established our claim.
Finally, letting Pâˆ—(Â·|y) = xâˆ—(y) Â· Î´Sâˆ’1({y}) for all y âˆˆÏ‰, where xâˆ—is the solution of
Eq. (2), achieves the optimum value in Eq. (2).
30
