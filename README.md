# Watermarking in LLMs Research Project

This repository contains research materials and code for studying watermarking techniques in Large Language Models (LLMs).

## Project Setup

### Environment Setup
The project uses a Conda environment for dependency management. To set up the environment:

```bash
# Create and activate conda environment from environment.yml
conda env create -f environment.yml
conda activate watermark

# For macOS users, install tesseract using Homebrew
brew install tesseract
```

If you need to update the environment after changes to `environment.yml`:
```bash
conda env update -f environment.yml
```

### API Configuration
Before running the analysis scripts, set up your Anthropic API key:
```bash
# Option 1: Export as environment variable
export ANTHROPIC_API_KEY='your-api-key-here'

# Option 2: Create .env file
echo "ANTHROPIC_API_KEY=your-api-key-here" > .env
```

## Data Collection and Processing

### 1. Fetching Paper Abstracts
We've implemented a script to automatically fetch paper abstracts from arXiv. The script:
- Extracts arXiv IDs from markdown files
- Fetches paper information including titles, abstracts, and authors
- Stores the data in structured JSON format

To fetch the abstracts:
```bash
python scripts/fetch_arxiv_abstracts.py
```

The fetched data is stored in [`data/abstract/papers_info.json`](data/abstract/papers_info.json) with the following structure:
```json
{
  "title": "Paper Title",
  "abstract": "Paper Abstract",
  "authors": ["Author 1", "Author 2"],
  "arxiv_id": "XXXX.XXXXX",
  "url": "https://arxiv.org/abs/XXXX.XXXXX"
}
```

Example of actual fetched data:
```json
{
  "title": "Is Watermarking LLM-Generated Code Robust?",
  "abstract": "We present the first study of the robustness of existing 
  watermarking\ntechniques on Python code generated by large language models. Although 
  existing\nworks showed that watermarking can be robust for natural language, we show 
  that\nit is easy to remove these watermarks on code by 
  semantic-preserving\ntransformations.",
  "authors": [
    "Tarun Suresh",
    "Shubham Ugare",
    "Gagandeep Singh",
    "Sasa Misailovic"
  ],
  "arxiv_id": "2403.17983",
  "url": "https://arxiv.org/abs/2403.17983"
}
```

### 2. PDF Text Extraction
We've implemented a script to extract text from PDF papers using PyMuPDF and Tesseract OCR:
- Processes all PDFs in the `papers/` directory
- Uses PyMuPDF for text extraction
- Falls back to Tesseract OCR for scanned pages
- Saves extracted text in `data/text/` directory
- Maintains detailed logs in `logs/` directory

To process PDFs:
```bash
python scripts/pdf_to_text.py
```

The processing results are stored in:
- `data/text/*.txt`: Extracted text files
- `logs/pdf_processing_*.log`: Processing logs with timestamps

> Note: This implementation uses open-source tools (PyMuPDF and Tesseract) instead of commercial solutions like Mathpix. While this approach is cost-effective, it may not accurately capture mathematical formulas and equations. For research requiring precise mathematical content analysis, consider using specialized OCR services.

## Project Structure
```
.
├── data/
│   ├── abstract/
│   │   └── papers_info.json
│   └── text/
│       └── *.txt
├── results/
│   └── analysis/
│       └── *.json
├── logs/
│   └── *.log
├── papers/
│   └── *.pdf
├── scripts/
│   ├── analyze_papers.py
│   ├── fetch_arxiv_abstracts.py
│   └── pdf_to_text.py
├── environment.yml
└── README.md
```

## Review Paper Structure

### Proposed Structure for LLM Watermarking Review

1. **Introduction**
   - Background and motivation
   - Challenges in LLM watermarking
   - Scope of this review

2. **Preliminaries**
   - Basic concepts of LLM watermarking
   - Design objectives
     * Detectability
     * Quality preservation  
     * Robustness
     * Security

3. **Taxonomy of LLM Watermarking Approaches**
   - Token-level watermarking
   - Semantic-level watermarking 
   - Distribution-preserving watermarking
   - Multi-bit watermarking
   - Distortion-free watermarking

4. **Key Components and Techniques**
   - Watermark embedding methods
   - Detection algorithms
   - Statistical testing frameworks
   - Optimization strategies

5. **Evaluation and Benchmarking**
   - Evaluation metrics
   - Benchmark datasets
   - Experimental setups
   - Performance comparison

6. **Robustness Analysis**
   - Common attack vectors
     * Paraphrasing attacks
     * Translation attacks
     * Editing attacks
   - Defense mechanisms
   - Theoretical bounds

7. **Applications and Use Cases**
   - Content attribution
   - Copyright protection
   - Model ownership verification
   - Malicious use prevention

8. **Open Challenges and Future Directions**
   - Current limitations
   - Emerging research questions
   - Potential improvements
   - Future applications

9. **Conclusion**

## Paper Analysis

### Analysis Scripts
The project includes scripts for analyzing watermarking papers using Claude API:

```bash
# List available papers
python scripts/analyze_papers.py --list --input-dir data/text

# Analyze a single paper
python scripts/analyze_papers.py --mode single --papers "paper_name" --input-dir data/text

# Analyze multiple papers in batch
python scripts/analyze_papers.py --mode batch --papers "paper1" "paper2" --input-dir data/text
```

### Analysis Modes
1. **Single Paper Analysis**
   - Analyzes one paper at a time
   - Focuses on core contributions and technical details
   - Outputs to `results/analysis/analysis_[paper_name]_[timestamp].json`

2. **Batch Analysis**
   - Compares multiple papers (2-3 recommended)
   - Focuses on unique innovations and comparative strengths
   - Outputs to `results/analysis/batch_analysis_[paper_names]_[timestamp].json`

### Analysis Focus
The analysis particularly emphasizes:
- Key innovations and unique contributions
- Technical uniqueness compared to other approaches
- Comparative strengths and trade-offs

### Output Structure
Analysis results are stored in JSON format with timestamps:
```json
{
  "papers": ["paper1_name", "paper2_name"],
  "analysis": {
    "key_innovation": {
      "unique_contribution": "...",
      "difference_from_existing": "...",
      "novel_problem_solved": "..."
    },
    "technical_uniqueness": {
      "core_advantage": "...",
      "unique_features": "...",
      "special_capabilities": "..."
    },
    "comparative_strengths": {
      "advantages": "...",
      "improvements": "...",
      "trade_offs": "..."
    }
  }
}
```

## Literature Review

### Paper Categories

> Note: The following categorization is based on detailed analysis of paper titles and abstracts, providing a structured overview of current research directions in LLM watermarking.

1. **Text Watermarking Methods**
   - Focus on embedding detectable but quality-preserving watermarks in LLM-generated text
   - Papers:
     * ["A Watermark for Large Language Models"](papers/A_Watermark_for_Large_Language_Models.pdf)
     * ["Adversarial Watermarking Transformer"](papers/Adversarial_Watermarking_Transformer.pdf)
     * ["Robust Distortion-free Watermarks"](papers/Robust_Distortion_free_Watermarks.pdf)
     * ["Undetectable Watermarks for Language Models"](papers/Undetectable_Watermarks.pdf)
     * ["Three Bricks to Consolidate Watermarks"](papers/Three_Bricks_to_Consolidate_Watermarks.pdf)
     * ["Embarrassingly Simple Text Watermarks"](papers/Embarrassingly_Simple_Text_Watermarks.pdf)
     * ["Improving the Generation Quality of Watermarked Large Language Models"](papers/Improving_the_Generation_Quality_of_Watermarked.pdf)
     * ["Towards Codable Watermarking"](papers/Towards_Codable_Text_Watermarking.pdf)
     * ["Watermarking Text Generated by Black-Box Language Models"](papers/Watermarking_Text_Generated_by_Black_Box.pdf)
     * ["CATER: Intellectual Property Protection"](papers/CATER.pdf)
     * ["A Semantic Invariant Robust Watermark"](papers/A_Semantic_Invariant_Robust_Watermark.pdf)
     * ["Distillation-Resistant Watermarking"](papers/Distillation_Resistant_Watermarking.pdf)
     * ["SemStamp: A Semantic Watermark"](papers/SemStamp.pdf)
     * ["Adaptive Text Watermark"](papers/Adaptive_Text_Watermark.pdf)
     * ["An Unforgeable Publicly Verifiable Watermark"](papers/An_Unforgeable_Publicly_Verifiable_Watermark.pdf)
     * ["Necessary and Sufficient Watermark"](papers/Necessary_and_Sufficient_Watermark.pdf)
     * ["k-SemStamp: A Clustering-Based Semantic Watermark"](papers/k_SemStamp.pdf)
     * ["WatME: Towards Lossless Watermarking"](papers/WatME_Towards_Lossless_Watermarking.pdf)
     * ["Token-Specific Watermarking"](papers/Token_Specific_Watermarking.pdf)
     * ["Advancing Beyond Identification: Multi-bit Watermark"](papers/Advancing_Beyond_Identification.pdf)
     * ["WaterMax: Breaking the LLM Watermark Trade-off"](papers/WaterMax.pdf)
     * ["Provably Robust Multi-bit Watermarking"](papers/Provably_Robust_Multi_bit_Watermarking.pdf)
     * ["Excuse me, sir? Your language model is leaking"](papers/Your_Language_Model_is_Leaking.pdf)

2. **Watermark Robustness and Evaluation**
   - Focus on attack resistance, robustness assessment, and performance evaluation
   - Papers:
     * ["Watermarks in the Sand: Impossibility of Strong Watermarking"](papers/Watermarks_in_the_Sand.pdf)
     * ["Is Watermarking LLM-Generated Code Robust?"](papers/Is_Watermarking_LLM_Generated_Code_Robust.pdf)
     * ["On the Learnability of Watermarks"](papers/On_the_Learnability_of_Watermarks.pdf)
     * ["On the Reliability of Watermarks"](papers/On_the_Reliability_of_Watermarks.pdf)
     * ["No Free Lunch in LLM Watermarking"](papers/No_Free_Lunch_in_LLM_Watermarking.pdf)
     * ["Who Wrote this Code? Watermarking for Code Generation"](papers/Who_Wrote_this_Code.pdf)
     * ["Can Watermarks Survive Translation?"](papers/Can_Watermarks_Survive_Translation.pdf)
     * ["Watermarking Makes Language Models Radioactive"](papers/Watermarking_Makes_Language_Models_Radioactive.pdf)
     * ["Downstream Trade-offs of Text Watermarks"](papers/Downstream_Trade_offs.pdf)
     * ["Provable Robust Watermarking"](papers/Provable_Robust_Watermarking.pdf)
     * ["Lost in Overlap: Exploring Watermark Collision"](papers/Lost_in_Overlap.pdf)
     * ["Watermarking Conditional Text Generation"](papers/Watermarking_Conditional_Text_Generation.pdf)
     * ["New Evaluation Metrics for LLM Watermarking"](papers/New_Evaluation_Metrics.pdf)
     * ["Mark My Words: Analyzing and Evaluating Watermarks"](papers/Mark_My_Words.pdf)
     * ["WaterBench: Towards Holistic Evaluation"](papers/WaterBench.pdf)
     * ["WaterJudge: Quality-Detection Trade-off"](papers/WaterJudge.pdf)

3. **Neural Network and Embedding Space Watermarking**
   - Focus on protecting model intellectual property through network-level watermarking
   - Papers:
     * ["EmMark: Robust Watermarks for IP Protection"](papers/EmMark.pdf)
     * ["Are You Copying My Model?"](papers/Are_You_Copying_My_Model.pdf)
     * ["Watermarking LLMs with Weight Quantization"](papers/Watermarking_LLMs_with_Weight_Quantization.pdf)
     * ["Functional Invariants to Watermark Large Transformers"](papers/Functional_Invariants_to_Watermark.pdf)
     * ["Instructional Fingerprinting"](papers/Instructional_Fingerprinting.pdf)
     * ["Proving membership in LLM pretraining data"](papers/Proving_Membership.pdf)
     * ["Cross-Attention Watermarking"](papers/Cross_Attention_Watermarking.pdf)
     * ["Baselines for Identifying Watermarked LLMs"](papers/Baselines_for_Identifying_Watermarked.pdf)
     * ["Watermarking Text Data on Large Language Models"](papers/Watermarking_Text_Data_on_Large_Language_Models.pdf)
     * ["WARDEN: Multi-Directional Backdoor Watermarks"](papers/WARDEN.pdf)

4. **Watermark Performance Optimization**
   - Focus on improving watermark efficiency and reducing quality impact
   - Papers:
     * ["Duwak: Dual Watermarks"](papers/Duwak_Dual_Watermarks.pdf)
     * ["Optimizing watermarks for large language models"](papers/Optimizing_Watermarks.pdf)
     * ["GumbelSoft: Diversified Language Model Watermarking"](papers/GumbelSoft.pdf)
     * ["Permute-and-Flip: An optimally robust decoder"](papers/Permute_and_Flip.pdf)
     * ["Multi-Bit Distortion-Free Watermarking"](papers/Multi_Bit_Distortion_Free_Watermarking.pdf)
     * ["Towards Better Statistical Understanding"](papers/Towards_Better_Statistical_Understanding.pdf)
     * ["A Statistical Framework of Watermarks"](papers/A_Statistical_Framework_of_Watermarks.pdf)
     * ["Robust Multi-bit Natural Language Watermarking"](papers/Robust_Multi_bit_Natural_Language_Watermarking.pdf)
     * ["REMARK-LLM: A Robust and Efficient Framework"](papers/REMARK_LLM.pdf)
     * ["Protecting Language Generation via Invisible Watermarking"](papers/Protecting_Language_Generation_Models.pdf)

5. **Image Watermarking**
   - Focus on watermarking techniques for generative image models
   - Papers:
     * ["Leveraging Optimization for Adaptive Attacks"](papers/Leveraging_Optimization_for_Adaptive_Attacks.pdf)
     * ["Catch You Everything Everywhere"](papers/Catch_You_Everything_Everywhere.pdf)
     * ["Hey That's Mine: Imperceptible Watermarks"](papers/Hey_Thats_Mine.pdf)
     * ["Generative Watermarking Against Unauthorized Synthesis"](papers/Generative_Watermarking.pdf)
     * ["Invisible Image Watermarks Are Provably Removable"](papers/Invisible_Image_Watermarks_Are_Provably_Removable.pdf)
     * ["Tree-Ring Watermarks"](papers/Tree_Ring_Watermarks.pdf)
     * ["Evading Watermark based Detection"](papers/Evading_Watermark.pdf)
     * ["The Stable Signature: Rooting Watermarks"](papers/The_Stable_Signature.pdf)
     * ["Watermarking Images in Self-Supervised Latent Spaces"](papers/Watermarking_Images_in_Self_Supervised_Latent_Spaces.pdf)

6. **Survey Papers**
   - Comprehensive reviews of LLM watermarking techniques
   - Papers:
     * ["A Survey of Text Watermarking in the Era of Large Language Models"](papers/A_Survey_of_Text_Watermarking.pdf)

> Note: Some papers may span multiple categories due to their comprehensive nature. The categorization aims to highlight each paper's primary focus while acknowledging potential overlap between categories.
