# Watermarking in LLMs Research Project

This repository contains research materials and code for studying watermarking techniques in Large Language Models (LLMs).

## Project Setup

### Environment Setup
The project uses a Conda environment for dependency management. To set up the environment:

```bash
# Create and activate conda environment
conda create -n watermark python=3.9
conda activate watermark

# Install required packages
pip install arxiv
```

## Data Collection

### Fetching Paper Abstracts
We've implemented a script to automatically fetch paper abstracts from arXiv. The script:
- Extracts arXiv IDs from markdown files
- Fetches paper information including titles, abstracts, and authors
- Stores the data in structured JSON format

To fetch the abstracts:
```bash
python scripts/fetch_arxiv_abstracts.py
```

The fetched data is stored in [`data/abstract/papers_info.json`](data/abstract/papers_info.json) with the following structure:
```json
{
  "title": "Paper Title",
  "abstract": "Paper Abstract",
  "authors": ["Author 1", "Author 2"],
  "arxiv_id": "XXXX.XXXXX",
  "url": "https://arxiv.org/abs/XXXX.XXXXX"
}
```

Example of actual fetched data:
```json
{
  "title": "Is Watermarking LLM-Generated Code Robust?",
  "abstract": "We present the first study of the robustness of existing watermarking\ntechniques on Python code generated by large language models. Although existing\nworks showed that watermarking can be robust for natural language, we show that\nit is easy to remove these watermarks on code by semantic-preserving\ntransformations.",
  "authors": [
    "Tarun Suresh",
    "Shubham Ugare",
    "Gagandeep Singh",
    "Sasa Misailovic"
  ],
  "arxiv_id": "2403.17983",
  "url": "https://arxiv.org/abs/2403.17983"
}
```

## Project Structure
```
.
├── data/
│   └── abstract/
│       └── papers_info.json
├── papers/
│   └── Awesome-LLM-Watermark.md
├── scripts/
│   └── fetch_arxiv_abstracts.py
├── environment.yml
└── README.md
```