# Watermarking in LLMs Research Project

This repository contains research materials and code for studying watermarking techniques in Large Language Models (LLMs).

## Project Setup

### Environment Setup
The project uses a Conda environment for dependency management. To set up the environment:

```bash
# Create and activate conda environment
conda create -n watermark python=3.9
conda activate watermark

# Install required packages
pip install arxiv
```

## Data Collection

### Fetching Paper Abstracts
We've implemented a script to automatically fetch paper abstracts from arXiv. The script:
- Extracts arXiv IDs from markdown files
- Fetches paper information including titles, abstracts, and authors
- Stores the data in structured JSON format

To fetch the abstracts:
```bash
python scripts/fetch_arxiv_abstracts.py
```

The fetched data is stored in [`data/abstract/papers_info.json`](data/abstract/papers_info.json) with the following structure:
```json
{
  "title": "Paper Title",
  "abstract": "Paper Abstract",
  "authors": ["Author 1", "Author 2"],
  "arxiv_id": "XXXX.XXXXX",
  "url": "https://arxiv.org/abs/XXXX.XXXXX"
}
```

Example of actual fetched data:
```json
{
  "title": "Is Watermarking LLM-Generated Code Robust?",
  "abstract": "We present the first study of the robustness of existing watermarking\ntechniques on Python code generated by large language models. Although existing\nworks showed that watermarking can be robust for natural language, we show that\nit is easy to remove these watermarks on code by semantic-preserving\ntransformations.",
  "authors": [
    "Tarun Suresh",
    "Shubham Ugare",
    "Gagandeep Singh",
    "Sasa Misailovic"
  ],
  "arxiv_id": "2403.17983",
  "url": "https://arxiv.org/abs/2403.17983"
}
```

## Project Structure
```
.
├── data/
│   └── abstract/
│       └── papers_info.json
├── papers/
│   └── Awesome-LLM-Watermark.md
├── scripts/
│   └── fetch_arxiv_abstracts.py
├── environment.yml
└── README.md
```

## Literature Review

### Paper Categories

> Note: The following categorization is generated by Moonshot AI, providing a structured overview of current research directions in LLM watermarking. The classification is based on paper abstracts only, without reviewing the full content of the papers.

1. **Robustness and Detection Capability of Watermarks**:
   - "Is Watermarking LLM-Generated Code Robust?"
   - "Towards Better Statistical Understanding of Watermarking LLMs"
   - "A Statistical Framework of Watermarks for Large Language Models: Pivot, Detection Efficiency and Optimal Rules"
   - "No Free Lunch in LLM Watermarking: Trade-offs in Watermarking Design Choices"

2. **Watermark Algorithm Design and Optimization**:
   - "WatME: Towards Lossless Watermarking Through Lexical Redundancy"
   - "Topic-Based Watermarks for LLM-Generated Text"
   - "WaterJudge: Quality-Detection Trade-off when Watermarking Large Language Models"
   - "Duwak: Dual Watermarks in Large Language Models"
   - "WaterMax: Breaking the LLM Watermark Detectability-Robustness-Quality Trade-off"
   - "Multi-Bit Distortion-Free Watermarking for Large Language Models"
   - "Provably Robust Multi-bit Watermarking for AI-generated Text"
   - "Instructional Fingerprinting of Large Language Models"
   - "Adaptive Text Watermark for Large Language Models"
   - "Improving the Generation Quality of Watermarked Large Language Models via Word Importance Scoring"
   - "Downstream Trade-offs of a Family of Text Watermarks"
   - "WaterBench: Towards Holistic Evaluation of Watermarks for Large Language Models"
   - "REMARK-LLM: A Robust and Efficient Watermarking Framework for Generative Large Language Models"
   - "Embarrassingly Simple Text Watermarks"
   - "Necessary and Sufficient Watermark for Large Language Models"
   - "Functional Invariants to Watermark Large Transformers"
   - "Watermarking LLMs with Weight Quantization"
   - "A Resilient and Accessible Distribution-Preserving Watermark for Large Language Models"
   - "A Semantic Invariant Robust Watermark for Large Language Models"
   - "SemStamp: A Semantic Watermark with Paraphrastic Robustness for Text Generation"
   - "Advancing Beyond Identification: Multi-bit Watermark for Large Language Models"
   - "Three Bricks to Consolidate Watermarks for Large Language Models"
   - "Towards Codable Watermarking for Injecting Multi-bits Information to LLMs"
   - "An Unforgeable Publicly Verifiable Watermark for Large Language Models"
   - "Robust Distortion-free Watermarks for Language Models"
   - "Watermarking Conditional Text Generation for AI Detection"
   - "Provable Robust Watermarking for AI-Generated Text"
   - "Undetectable Watermarks for Language Models"
   - "Watermarking Text Data on Large Language Models for Dataset Copyright"
   - "Baselines for Identifying Watermarked Large Language Models"
   - "Who Wrote this Code? Watermarking for Code Generation"
   - "Robust Multi-bit Natural Language Watermarking through Invariant Features"
   - "Are You Copying My Model? Protecting the Copyright of Large Language Models for EaaS via Backdoor Watermark"
   - "Watermarking Text Generated by Black-Box Language Models"
   - "Protecting Language Generation Models via Invisible Watermarking"
   - "A Watermark for Large Language Models"
   - "Distillation-Resistant Watermarking for Model Protection in NLP"
   - "CATER: Intellectual Property Protection on Text Generation APIs via Conditional Watermarks"

3. **Semantic Consistency and Quality Preservation**:
   - "WatME: Towards Lossless Watermarking Through Lexical Redundancy"
   - "Improving the Generation Quality of Watermarked Large Language Models via Word Importance Scoring"

4. **Cross-lingual and Cross-modal Applications**:
   - "Can Watermarks Survive Translation? On the Cross-lingual Consistency of Text Watermark for Large Language Models"

5. **Security and Privacy Issues**:
   - "WARDEN: Multi-Directional Backdoor Watermarks for Embedding-as-a-Service Copyright Protection"
   - "EmMark: Robust Watermarks for IP Protection of Embedded Quantized Large Language Models"
   - "Watermarking Text Data on Large Language Models for Dataset Copyright"

6. **Attack and Defense Mechanisms**:
   - "Lost in Overlap: Exploring Watermark Collision in LLMs"
   - "Evading Watermark based Detection of AI-Generated Content"

7. **Evaluation and Benchmarking**:
   - "WaterJudge: Quality-Detection Trade-off when Watermarking Large Language Models"
   - "Mark My Words: Analyzing and Evaluating Language Model Watermarks"
   - "WaterBench: Towards Holistic Evaluation of Watermarks for Large Language Models"